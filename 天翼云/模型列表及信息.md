| 平台 | 地址 | 免费token数 | 有效期 | 活动 | 备注说明 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 欧派算力云 | [ppinfra.com](https://ppinfra.com/user/register?invited_by=HPU4F4) | 新用户注册5￥<br>邀请注册得15￥ | 6月 | 邀请 1 位好友注册并完成实名认证，邀请人可得 30元无门槛代金券，被邀请人可得 15元无门槛代金券 | 可以使用前面我的要求链接<br>感谢 |
>**已支持Kimi K2 Instruct**

| 图标 | 模型名称 | 标签 | 分类 | 系列/来源 | 类型 | 框架 | 描述 | 操作 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-0528 | 新品上架 | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-R1-0528是DeepSeek团队推出的最新版模型。模型基于 DeepSeek-V3-0324 训练，参数量达660B。该模型通过利用增加的计算资源并在后训练期间引入算法优化机制，显著提高了其推理和推理能力的深度。该模型在各种基准测试评估中表现出出色的性能，包括数学、编程和一般逻辑。它的整体性能现在接近 O3 和 Gemini 2.5 Pro 等领先机型。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-V3-0324 | 新品上架 | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-V3-0324是DeepSeek团队于2025年3月24日发布的DeepSeek-V3语言模型的新版本。是一个专家混合（MoE）语言模型，总参数为6710亿个，每个Token激活了370亿个参数。0324版本开创了一种用于负载均衡的辅助无损策略，并设定了多令牌预测训练目标以提高性能。该模型版本在几个关键方面比其前身DeepSeek-V3有了显著改进。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-235B-A22B | 热门使用 | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen3-235B-A22B是Qwen3系列大型语言模型的旗舰模型。拥有2350多亿总参数和220多亿激活参数。在代码、数学、通用能力等基准测试中，与DeepSeek-R1、o1、o3-mini、Grok-3和Gemini-2.5-Pro等顶级模型相比，表现出极具竞争力的结果。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-30B-A3B | | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen3是Qwen 系列最新一代大型语言模型，提供了一系列密集型和专家混合（MoE）模型。基于广泛的训练，Qwen3 在推理、指令执行、代理能力和多语言支持方面实现了突破性进展 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-昇腾版 | 新品上架 | 文本生成 | DeepSeek | | PyTorch | DeepSeek-R1是一款具有671B参数大小的创新性大语言模型，该模型基于transformer架构，通过对海量语料数据进行预训练，结合注意力机制，经过监督微调、人类反馈的强化学习等技术进行对齐，具备语义分析、计算推理、问答对话、篇章生成、代码编写等多种能力。R1模型在多个NLP基准测试中表现出色，具备较强的泛化能力和适应性。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-V3-昇腾版 | 新品上架 | 文本生成 | DeepSeek | | PyTorch | DeepSeek-V3是DeepSeek团队开发的新一代专家混合（MoE）语言模型，共有671B参数，在14.8万亿个Tokens上进行预训练。该模型采用多头潜在注意力（MLA）和DeepSeekMoE架构，继承了DeepSeek-V2模型的优势，并在性能、效率和功能上进行了显著提升。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-32B | 新品上架 | 文本生成 | 阿里 | | PyTorch | Qwen3是Qwen系列中最新一代的大型语言模型，提供一整套密集（Dense）模型和混合专家（MoE）模型。Qwen3基于广泛的培训而构建，在推理、指令遵循、代理功能和多语言支持方面取得了突破性的进步。Qwen3-32B是参数量为32.8B的密集（Dense）模型。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-14B | | 文本生成 | 阿里 | | PyTorch | Qwen3是Qwen系列中最新一代的大型语言模型，提供一整套密集（Dense）模型和混合专家（MoE）模型。Qwen3基于广泛的培训而构建，在推理、指令遵循、代理功能和多语言支持方面取得了突破性的进步。Qwen3-14B是参数量为14.8B的密集（Dense）模型。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-8B | | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen3是Qwen系列中最新一代的大型语言模型，提供一整套密集（Dense）模型和混合专家（MoE）模型。Qwen3基于广泛的培训而构建，在推理、指令遵循、代理功能和多语言支持方面取得了突破性的进步。Qwen3-8B是参数量为82亿的密集（Dense）模型。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen3-4B | | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen3是Qwen 系列最新一代大型语言模型，提供了一系列密集型和专家混合（MoE）模型。基于广泛的训练，Qwen3 在推理、指令执行、代理能力和多语言支持方面实现了突破性进展 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2.5-VL-72B-Instruct | 热门使用 | 图像理解 | 阿里 | | PyTorch | Qwen2.5-VL-72B-Instruct模型是阿里云通义千问开源的全新视觉模型，具有720亿参数规模，以满足高性能计算场景的需求。目前共推出3B、7B、32B和72B四个尺寸的版本。这是旗舰版Qwen2.5-VL-72B的指令微调模型，在13项权威评测中夺得视觉理解冠军，全面超越GPT-40与Claude3.5。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | QwQ-32B | 新品上架 | 文本生成 | 阿里 | 通用模型 | PyTorch | QwQ-32B是一款拥有 320 亿参数的推理模型，其性能可与具备 6710 亿参数（其中 370 亿被激活）的 DeepSeek-R1 媲美。该模型集成了与Agent相关的能力，使其能够在使用工具的同时进行批判性思考，并根据环境反馈调整推理过程。 | 评估, API文档, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-Distill-Llama-70B | 新品上架 | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-R1-Distill-Llama-70B是基于Llama架构并经过强化学习和蒸馏优化开发的高性能语言模型。该模型融合了DeepSeek-R1的先进知识蒸馏技术与Llama-70B模型的架构优势。通过知识蒸馏，在保持较小参数规模的同时，具备强大的语言理解和生成能力。 | 评估, API文档, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-Distill-Qwen-32B | 新品上架 | 文本生成 | DeepSeek | | PyTorch | DeepSeek-R1-Distill-Qwen-32B是通过知识蒸馏技术从DeepSeek-R1模型中提炼出来的小型语言模型。它继承了DeepSeek-R1的推理能力，专注于数学和逻辑推理任务，但体积更小，适合资源受限的环境。 | 评估, API文档, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-Distill-Qwen-14B | 新品上架 | 文本生成 | DeepSeek | | PyTorch | DeepSeek-R1-Distill-Qwen-14B是通过知识蒸馏技术从DeepSeek-R1模型中提炼出来的小型语言模型。它继承了DeepSeek-R1的推理能力，专注于数学和逻辑推理任务，但体积更小，适合资源受限的环境。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-Distill-Qwen-7B | 新品上架 | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-R1-Distill-Qwen-7B是通过知识蒸馏技术从DeepSeek-R1模型中提炼出来的小型语言模型。它继承了DeepSeek-R1的推理能力，专注于数学和逻辑推理任务，但体积更小，适合资源受限的环境。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-Distill-Qwen-1.5B | 新品上架 | 文本生成 | DeepSeek | 通用模型 | | DeepSeek-R1-Distill-Qwen-1.5B是通过知识蒸馏技术从DeepSeek-R1模型中提炼出来的小型语言模型。它继承了DeepSeek-R1的推理能力，专注于数学和逻辑推理任务，但体积更小，适合资源受限的环境。 | 精调, 评估, 部署 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | BGE-Reranker-Large | 新品上架 | 向量模型 | 其他 | | | BGE-Reranker-Large是北京智源人工智能研究院（BAAI）发布的一款基于深度学习的重排序模型，能够在中英文两种语言环境下，对检索结果进行优化，提高检索的准确性和相关性。与嵌入模型不同，Reranker使用question和document作为输入，直接输出相似度而不是嵌入。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | BGE-m3 | | 向量模型 | 其他 | 通用模型 | | BGE-m3是智源发布的通用语义向量模型BGE家族新成员，支持超过100种语言，具备领先的多语言、跨语言检索能力，全面且高质量地支撑“句子”、“段落”、“篇章”、“文档”等不同粒度的输入文本，最大输入长度为8192，并且一站式集成了稠密检索、稀疏检索、多向量检索三种检索功能，在多个评测基准中达到最优水平。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | TeleChat-12B | 热门使用 | 文本生成 | 中国电信人工智能 | 通用模型 | PyTorch | 星辰语义大模型TeleChat是由中电信人工智能科技有限公司研发训练的大语言模型，TeleChat-12B模型基座采用3万亿 Tokens中英文高质量语料进行训练。TeleChat-12B-bot在模型结构、训练数据、训练方法等方面进行了改进，在通用问答和知识类、代码类、数学类榜单上相比TeleChat-7B-bot均有大幅提升。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Baichuan2-Turbo | 热门使用 | 文本生成 | 百川智能 | 通用模型 | PyTorch | Baichuan-Turbo系列模型是百川智能推出的大语言模型，采用搜索增强技术实现大模型与领域知识、全网知识的全面链接。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2.5-72B-Instruct | 新品上架 | 文本生成 | 阿里 | | PyTorch | Qwen2.5系列发布了许多基本语言模型和指令调整语言模型，参数范围从0.5到720亿个参数不等。Qwen2.5-72B-Instruct模型是Qwen2.5系列大型语言模型指令调整版本。 | 评估, API文档, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2.5-32B-Instruct | 新品上架 | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen2.5系列发布了许多基本语言模型和指令调整语言模型，参数范围从0.5到720亿个参数不等。Qwen2.5-32B-Instruct模型是Qwen2.5系列大型语言模型指令调整版本。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2.5-Math-7B-Instruct | 新品上架 | 文本生成 | 阿里 | | PyTorch | Qwen2.5-Math系列是数学专项大语言模型Qwen2-Math的升级版。系列包括1.5B、7B、72B三种参数的基础模型和指令微调模型以及数学奖励模型Qwen2.5-Math-RM-72B，Qwen2.5-Math-7B-Instruct的性能与Qwen2-Math-72B-Instruct相当。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2-72B-Instruct | 热门使用 | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen2 是 Qwen 大型语言模型的新系列。Qwen2发布了5个尺寸的预训练和指令微调模型，包括Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B。这是指令调整的 72B Qwen2 模型，使用了大量数据对模型进行了预训练，并使用监督微调和直接偏好优化对模型进行了后训练。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2-7B-Instruct | 热门使用 | 文本生成 | 阿里 | | PyTorch | Qwen2-7B-Instruct是 Qwen2大型语言模型系列中覆盖70亿参数的指令调优语言模型，支持高达 131,072 个令牌的上下文长度，能够处理大量输入。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-72B-Chat | 热门使用 | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问1.5（Qwen1.5）是阿里云研发的通义千问系列开源模型，是一种基于 Transformer 的纯解码器语言模型，已在大量数据上进行了预训练。该系列包括Base和Chat等多版本、多规模，满足不同的计算需求，这是Qwen1.5-72B-Chat版本。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-32B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。这是Qwen1.5-32B-Chat版本。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-14B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问1.5（Qwen1.5）是阿里云研发的通义千问系列开源模型，是一种基于 Transformer 的纯解码器语言模型，已在大量数据上进行了预训练。该系列包括Base和Chat等多版本、多规模，满足不同的计算需求，这是Qwen1.5-14B-Chat版本。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-7B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问1.5（Qwen1.5）是阿里云研发的通义千问系列开源模型，是一种基于 Transformer 的纯解码器语言模型，已在大量数据上进行了预训练。该系列包括Base和Chat等多版本、多规模，满足不同的计算需求，这是Qwen1.5-7B-Chat版本。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-VL-Chat | 新品上架 | 图像理解 | 阿里 | 通用模型 | PyTorch | Qwen-VL-Chat模型是在阿里云研发的大规模视觉语言模型 Qwen-VL 系列的基础上，使用对齐机制打造的视觉AI助手，该模型有更优秀的中文指令跟随，支持更灵活的交互方式，包括多图、多轮问答、创作等能力。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Llama3-70B-Instruct | 热门使用 | 文本生成 | Meta | 通用模型 | PyTorch | Meta 开发并发布了 Meta Llama 3 系列大型语言模型 （LLM），包含 8B 和 70B 两种参数大小，Llama3-70B-Instruct 是经过指令微调的版本，针对对话用例进行了优化，在常见的行业基准测试中优于许多可用的开源聊天模型。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Llama3-8B-Instruct | 热门使用 | 文本生成 | Meta | 通用模型 | PyTorch | Meta 开发并发布了 Meta Llama 3 系列大型语言模型 （LLM），包含 8B 和 70B 两种参数大小，Llama3-8B-Instruct 是经过指令微调的版本，针对对话用例进行了优化，在常见的行业基准测试中优于许多可用的开源聊天模型。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-70B-Chat | | 文本生成 | Meta | 通用模型 | PyTorch | Llama 2 是预训练和微调的生成文本模型的集合，规模从 70 亿到 700 亿个参数不等。这是 70B 微调模型的存储库，针对对话用例进行了优化。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-13B-Chat | | 文本生成 | Meta | 通用模型 | PyTorch | Llama2是预先训练和微调的生成文本模型的集合，其规模从70亿到700亿个参数不等。这是13B微调模型的存储库，针对对话用例进行了优化。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | StableDiffusion-V2.1 | 新品上架 | 文本生图 | Stability AI | 通用模型 | PyTorch | StableDiffusion-V2.1是由 Stability AI 公司推出的基于深度学习的文生图模型，它能够根据文本描述生成详细的图像，同时也可以应用于其他任务，例如图生图，生成简短视频等。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Gemma2-9B-IT | 新品上架 | 文本生成 | Google | 通用模型 | PyTorch | Gemma2-9B-IT是Google最新发布的具有90亿参数的开源大型语言模型的指令调优版本。模型在大量文本数据上进行预训练，并且在性能上相较于前一代有了显著提升。该版本的性能在同类产品中也处于领先地位，超过了Llama3-8B和其他同规模的开源模型。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | InternLM2-Chat-7B | 热门使用 | 文本生成 | 其他 | 通用模型 | PyTorch | InternLM2-Chat-7B 是书生·浦语大模型系列中开源的 70 亿参数库模型和针对实际场景量身定制的聊天模型。InternLM2相比于初代InternLM，在推理、数学、代码等方面的能力提升尤为显著，综合能力领先于同量级开源模型。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | ChatGLM3-6B | 热门使用 | 文本生成 | 智谱AI | 通用模型 | PyTorch | ChatGLM3-6B 是 ChatGLM 系列最新一代的开源模型，在保留了前两代模型对话流畅、部署门槛低等众多优秀特性的基础上，ChatGLM3-6B 引入了更强大的基础模型、更完整的功能支持、更全面的开源序列几大特性。 | API文档, 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-V2-Lite-Chat | | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-V2-Lite-Chat是一款强大的开源专家混合（MoE）语言聊天模型，具有16B参数，2.4B活动参数，使用5.7T令牌从头开始训练，其特点是同时具备经济的训练和高效的推理。 | 评估, 部署, API文档, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | TeleChat2-35B | 热门使用 | 文本生成 | 中国电信人工智能 | 通用模型 | PyTorch | 星辰语义大模型TeleChat2-35B是由中国电信人工智能研究院研发训练的大语言模型，该模型完全基于国产算力训练，支持工具调用功能。在Function Call方面，针对性进行了效果优化，在相关榜单评测上相比同尺寸模型均有较好表现。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | TeleChat-7B | 热门使用 | 文本生成 | 中国电信人工智能 | 通用模型 | PyTorch | 星辰语义大模型TeleChat是由中电信人工智能科技有限公司研发训练的大语言模型，7B模型基座采用1.5万亿 Tokens中英文高质量语料进行训练。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | GLM4-9B-Chat | 新品上架 | 文本生成 | 智谱AI | 通用模型 | PyTorch | GLM4-9B-Chat是智谱AI推出的GLM4系列中的开源聊天版本，在语义、数学、推理、代码和知识等多方面的数据集测评中，GLM-4-9B-Chat模型表现出了超越Llama-3-8B的卓越性能。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Llama3.2-3B-Instruct | 新品上架 | 文本生成 | Meta | 通用模型 | | Meta Llama3.2多语言大型语言模型（LLMs）系列是一系列预训练及指令微调的生成模型，包含1B和3B参数规模。Llama3.2指令微调的纯文本模型专门针对多语言对话应用场景进行了优化，包括代理检索和摘要任务。它们在通用行业基准测试中超越了许多可用的开源和闭源聊天模型。这是Llama3.2-3B-Instruct版本。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | Llama3.1-8B-Instruct | 新品上架 | 文本生成 | Meta | 通用模型 | PyTorch | Llama3.1-8B-Instruct是Meta推出的多语言大型语言模型，基于优化的transformer架构，覆盖80亿参数。Llama3.1指令调整后的纯文本模型针对多语言对话使用案例进行了优化，在常见的行业基准上优于许多可用的开源和封闭式聊天模型。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | InternVL-Chat-V1.5 | 新品上架 | 图像理解 | 其他 | 通用模型 | PyTorch | InternVL-Chat-V1.5是一种开源多模态大型语言模型（MLLM），用于弥合开源和专有商业模型在多模态理解方面的能力差距。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | InternLM2-Chat-20B | | 文本生成 | 其他 | 通用模型 | PyTorch | InternLM2-Chat-20B 是书生·浦语大模型系列中开源的200 亿参数库模型和针对实际场景量身定制的聊天模型。InternLM2相比于初代InternLM，在推理、数学、代码等方面的能力提升尤为显著，综合能力领先于同量级开源模型。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2-1.5B-Instruct | | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen2 是 Qwen 大型语言模型的新系列。Qwen2发布了5个尺寸的预训练和指令微调模型，包括Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B。这是指令调整的 1.5B Qwen2 模型，使用了大量数据对模型进行了预训练，并使用监督微调和直接偏好优化对模型进行了后训练。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | CodeLlama-34B-Instruct | | 文本生成 | Meta | 场景模型 | MindSpore | CodeLlama-34B-Instruct模型是建立在Llama2之上的大型语言模型，针对生成和讨论代码进行了指令微调，规模为340亿个参数，该模型使开发人员的工作流程更快、更高效，并降低学习编码的人的入门门槛。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-7B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型。Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-7B的基础上，使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Llama3-8B-Chinese-Chat | | 文本生成 | Meta | 通用模型 | PyTorch | Llama3-8B-Chinese-Chat是基于Meta-Llama-3-8B-Instruct模型微调的中文聊天模型，其使用ORPO进行了中文微调， 显著减少了“中文问题英文回复”的现象，以及中英文混合的问题，并且减少了答案中表情符号的数量，使回复更加正式，增强了中文能力。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | ChatGLM2-6B | | 文本生成 | 智谱AI | 通用模型 | PyTorch | ChatGLM2-6B智谱AI与清华KEG实验室发布的中英双语对话模型，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM2-6B引入了新特征：更强大的性能、更长的上下文、更高效的推理、更开放的协议，在数理逻辑、知识推理、长文档理解上均有支持，在MMLU、CEval等数据集上相比初代有大幅的性能提升。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-72B | | 文本生成 | 阿里 | | MindSpore | Qwen1.5模型是通义千问推出的基于Transformer架构的开源语言模型系列1.5版本，包括0.5B、1.8B、4B、7B、14B、32B、72B和110B共计8个不同规模的Base和Chat模型，以及一个MoE模型，并同步放出了各尺寸模型对应的量化模型。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-Chinese-13B-Chat | | 文本生成 | 其他 | 通用模型 | PyTorch | Llama2-Chinese-13B-Chat模型是Llama 2 对话中文微调参数模型，基于 Meta 发布的 Llama2 Chat 开源模型来进行微调。由于 Llama 2 本身的中文对齐比较弱，开发者采用了中文指令集来进行微调，使其具备较强的中文对话能力。目前这个中文微调参数模型总共发布了 7B，13B两种参数大小。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Chinese-Alpaca-2-13B | | 文本生成 | 其他 | 通用模型 | PyTorch | Chinese-Alpaca-2-13B模型是基于 Meta 开源的 LLaMA 模型系列进行训练和优化的中文大模型。它在原版 LLaMA 模型的基础上扩充了中文词表，并使用大规模中文数据进行增量预训练，进一步提高了中文的基本语义理解。与第一代模型相比，性能有了显着提高。相关型号支持 4K 上下文，并且可以使用 NTK 方法扩展到 18K+。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-14B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问-14B（Qwen-14B） 是阿里云研发的通义千问大模型系列的140亿参数规模的模型。Qwen-14B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-14B的基础上，使用对齐机制打造了基于大语言模型的AI助手Qwen-14B-Chat。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-7B-Chat | | 文本生成 | Meta | 通用模型 | PyTorch | Llama2-7B-Chat是Meta AI开发的大型语言模型Llama2家族中最小的聊天模型。该模型有70亿个参数，并在来自公开来源的2万亿token数据上进行了预训练。它已经在超过一百万个人工注释的指令数据集上进行了微调。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-7B | | 文本生成 | 阿里 | 通用模型 | MindSpore | 通义千问-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型。Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-14B | | 文本生成 | 阿里 | 通用模型 | MindSpore | 通义千问-14B（Qwen-14B）是阿里云研发的通义千问大模型系列的140亿参数规模的模型。Qwen-14B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/4.4c798a01.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-7B | | 文本生成 | Meta | 通用模型 | MindSpore | Llama2-7B是Meta AI在2023年发布的7B规模版本的大型语言模型，旨在提供高质量的自然语言处理能力。该模型在预训练数据方面表现出色，使用了2万亿个标记进行训练，上下文长度扩展到了4096，这比Llama1的2048有所增加，使得模型能够理解和生成更长的文本。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-13B | | 文本生成 | Meta | 通用模型 | MindSpore | Llama2-13B是Meta AI在2023年发布的13B规模版本的大型语言模型，旨在提供高质量的自然语言处理能力。该模型在预训练数据方面表现出色，使用了2万亿个标记进行训练，上下文长度扩展到了4096，这比Llama1的2048有所增加，使得模型能够理解和生成更长的文本。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Llama2-70B | | 文本生成 | Meta | 通用模型 | MindSpore | Llama2-70B是Meta AI在2023年发布的70B规模版本的大型语言模型，旨在提供高质量的自然语言处理能力。该模型在预训练数据方面表现出色，使用了2万亿个标记进行训练，上下文长度扩展到了4096，这比Llama1的2048有所增加，使得模型能够理解和生成更长的文本。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | ChineseClip | | 图像理解 | 阿里 | 通用模型 | PyTorch | ChineseClip是一款基于大规模中文图像文本对数据集实现的多模态预训练模型，是对原始CLIP模型的中文适配和扩展。该模型能够执行跨模态检索，还可以作为零镜头图像分类、开放域对象检测等视觉任务的视觉支柱。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen-72B-Chat | | 文本生成 | 阿里 | 通用模型 | PyTorch | 通义千问-72B（Qwen-72B）是阿里云研发的通义千问大模型系列的720亿参数规模的模型。Qwen-72B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-72B的基础上，使用对齐机制打造了基于大语言模型的AI助手Qwen-72B-Chat。 | 部署, 评估, 精调 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Qwen1.5-1.8B-Chat | | 文本生成 | 阿里 | 通用模型 | | 通义千问1.5（Qwen1.5）是阿里云研发的通义千问系列开源模型，是一种基于Transformer的纯解码器语言模型，已在大量数据上进行了预训练。该系列包括Base和Chat等多版本、多规模，满足不同的计算需求，这是Qwen1.5-1.8B-Chat版本。 | 精调, 评估, 部署 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2-Math-72B-Instruct | 新品上架 | 文本生成 | 阿里 | 场景模型 | PyTorch | Qwen2-Math-72B-Instruct模型是基于Qwen2-Math-72B训练的一个特定于数学的奖励模型。Qwen2系列的数学专用大型语言模型包括Qwen2-Math和Qwen2-Math-Instruct-1.5B/7B/72B。该模型的数学能力明显优于开源模型甚至闭源模型（例如GPT-4o）。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | YOLOv7 | | 图像检测 | 其他 | 通用模型 | | YOLOv7（You Only Look Once version 7）是YOLO系列目标检测算法的版本之一。自YOLO系列诞生以来，它凭借其高效的实时性能和出色的检测精度，在目标检测领域取得了显著的成就。YOLOv7在继承YOLO系列优点的同时，进一步提升了算法的性能和速度，成为当前目标检测领域的新里程碑。 | 精调, 评估, 部署 |
| <img src="https://huiju.ctyun.cn/img/3.866d2cf3.svg?regionId=200000001852" width="30" alt="icon"> | InternLM2.5-7B-Chat | 新品上架 | 文本生成 | 其他 | 通用模型 | PyTorch | InternLM2.5-7B-Chat是书生·浦语大模型第2.5代开源的针对实际应用场景的，具有70亿参数的对话模型。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | ChatGLM3-6B-32K | | 文本生成 | 智谱AI | 通用模型 | | ChatGLM3-6B-32K模型在ChatGLM3-6B的基础上进一步强化了对于长文本的理解能力，能够更好的处理最多32K长度的上下文。具体对位置编码进行了更新，并设计了更有针对性的长文本训练方法，在对话阶段使用 32K 的上下文长度训练。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Gemma2-27B-IT | 新品上架 | 文本生成 | Google | 通用模型 | PyTorch | Gemma是来自谷歌的轻量级、最先进的开放模型家族，由用于创建双子座模型的相同研究和技术构建。它们是文本到文本的、仅限解码器的大型语言模型，提供英语版本，预训练变体和指令调整变体都有开放权重。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | CodeGemma-7B-IT | | 文本生成 | Google | 场景模型 | | CodeGemma是构建在Gemma之上的轻量级开放代码模型的集合。CodeGemma-7B-IT模型是CodeGemma系列模型之一，是一种文本到文本和文本到代码的解码器模型的指令调整变体，具有70亿参数，可用于代码聊天和指令跟随。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-Coder-V2-Lite-Instruct | | 文本生成 | DeepSeek | 场景模型 | | DeepSeek-Coder-V2-Lite-Instruct是一款强大的开源专家混合（MoE）语言聊天模型，具有16B参数，2.4B活动参数。该模型基于DeepSeek-V2进一步预训练，增加了6T Tokens，可在特定的代码任务中实现与GPT4-Turbo相当的性能。 | 精调, 评估, 部署, API文档 |
| <img src="https://huiju.ctyun.cn/img/1.c0d2844f.svg?regionId=200000001852" width="30" alt="icon"> | Mixtral-8x7B-Instruct-V0.1 | | 文本生成 | Mistral AI | 通用模型 | | Mixtral-8x7B-Instruct-V0.1是由Mistral AI开发的采用稀疏混合专家机制的大语言模型，旨在解决大规模语言处理任务中的效率问题。该模型采用了Transformer架构，并在其中引入了混合专家层（Mixture-of-Expert layer），从而实现了高效的并行计算和可扩展性。 | 精调, 评估, 部署 |
| <img src="https://huiju.ctyun.cn/img/2.4ec0c668.svg?regionId=200000001852" width="30" alt="icon"> | MiniCPM-Llama3-V-2.5 | | 文本生成 | 其他 | | | MiniCPM-Llama3-V-2.5是建立在SigLip-400M和Llama3-8B-Instruct基础上的模型型号，共有8B参数。与MiniCPM-V2.0相比，它的性能有了显著提高。在基准测试的综合评估中，超越了GPT-4V-1106、Gemini Pro、Claude3和Qwen-VL-Max等广泛使用的专有模型，并大大优于其他基于Llama3的MLLM。 | 精调, 评估, 部署 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | Qwen2-57B-A14B-Instruct | 新品上架 | 文本生成 | 阿里 | 通用模型 | PyTorch | Qwen2是Qwen1.5大型语言模型系列的升级。共发布了5个尺寸的预训练和指令微调模型，包括Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B。Qwen2-57B-A14B-Instruct是Qwen2-57B-A14B的指令微调模型，使用了大量数据对模型进行了预训练，并使用监督微调和直接偏好优化对模型进行了后训练。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/5.8432ea8b.svg?regionId=200000001852" width="30" alt="icon"> | InternVL2-8B | 新品上架 | 图像理解 | 其他 | 通用模型 | PyTorch | InternVL2.0是InternVL系列多模态大语言模型的新版本，提供了多种指令微调的模型，参数从10亿到1080亿不等。InternVL2-8B是参数为80亿的模型。与最先进的开源多模态大语言模型相比，InternVL2.0超越了大多数开源模型。 | 评估, 部署, 精调 |
| <img src="https://huiju.ctyun.cn/img/6.7e77120f.svg?regionId=200000001852" width="30" alt="icon"> | DeepSeek-R1-昇腾版2 | 新品上架 | 文本生成 | DeepSeek | 通用模型 | PyTorch | DeepSeek-R1是一款具有671B参数大小的创新性大语言模型，该模型基于transformer架构，通过对海量语料数据进行预训练，结合注意力机制，经过监督微调、人类反馈的强化学习等技术进行对齐，具备语义分析、计算推理、问答对话、篇章生成、代码编写等多种能力。R1 模型在多个 NLP 基准测试中表现出色，具备较强的泛化能力和适应性。 | 精调, 评估, 部署, API文档 |
> 2025-7-16 14:34:19
>
> | 平台     | 地址                                                         | 免费token数    | 有效期 | 活动                                                         | 备注说明                                                   |
> | :------- | :----------------------------------------------------------- | :------------- | :----- | :----------------------------------------------------------- | :--------------------------------------------------------- |
> | 硅基流动 | [cloud.siliconflow.cn](https://cloud.siliconflow.cn/i/NpVqAT7X) | 2000万（14元） | 无     | **学生认证50元巨款**<br>邀请注册送14￥白嫖<br>可用使用前面我的链接注册（感谢） | 白嫖开始的地方<br>速度现在还好，之前慢<br>配额一直有效<br> |

| Tag                                 | Logo                                                         | 模型/服务名称                                   | 厂商/提供方     | 价格       | 价格单位   | 图标                | 简介       | 标签1                                                        | 标签2          | 标签3        | 标签4        | 标签5        | 标签6        | 标签7                                             | 标签8                                         | 标签9      |
| :---------------------------------- | :----------------------------------------------------------- | :---------------------------------------------- | :-------------- | :--------- | :--------- | :------------------ | :--------- | :----------------------------------------------------------- | :------------- | :----------- | :----------- | :----------- | :----------- | :------------------------------------------------ | :-------------------------------------------- | :--------- |
| DeepSeek-R1-0528 × 华为云昇腾云服务 | ![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml) | deepseek-ai/DeepSeek-R1                         | DeepSeek        | ￥         | 16         | / M Tokens          | 💰🎁         | DeepSeek-R1-0528 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。 | 对话           | FIM          | Tools        | 推理模型     | MoE          |                                                   |                                               |            |
| DeepSeek-R1-0528 × 华为云昇腾云服务 | ![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml) | Pro/deepseek-ai/DeepSeek-R1                     | DeepSeek        | ￥         | 16         | / M Tokens          | 💰          | DeepSeek-R1-0528 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。 | 对话           | FIM          | Tools        | 推理模型     | MoE          |                                                   |                                               |            |
| DeepSeek-V3-0324                    | ![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml) | deepseek-ai/DeepSeek-V3                         | DeepSeek        | ￥         | 8          | / M Tokens          | 💰🎁         | 新版 DeepSeek-V3 （DeepSeek-V3-0324）与之前的 DeepSeek-V3-1226 使用同样的 base 模型，仅改进了后训练方法。新版 V3 模型借鉴 DeepSeek-R1 模型训练过程中所使用的强化学习技术，大幅提高了在推理类任务上的表现水平，在数学、代码类相关评测集上取得了超过 GPT-4.5 的得分成绩。此外该模型在工具调用、角色扮演、问答闲聊等方面也得到了一定幅度的能力提升。 | 对话           | FIM          | Tools        | MoE          | 671B         |                                                   |                                               |            |
| DeepSeek-V3-0324                    | ![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml) | Pro/deepseek-ai/DeepSeek-V3                     | DeepSeek        | ￥         | 8          | / M Tokens          | 💰          | 新版 DeepSeek-V3 （DeepSeek-V3-0324）与之前的 DeepSeek-V3-1226 使用同样的 base 模型，仅改进了后训练方法。新版 V3 模型借鉴 DeepSeek-R1 模型训练过程中所使用的强化学习技术，大幅提高了在推理类任务上的表现水平，在数学、代码类相关评测集上取得了超过 GPT-4.5 的得分成绩。此外该模型在工具调用、角色扮演、问答闲聊等方面也得到了一定幅度的能力提升。 | 对话           | FIM          | Tools        | MoE          | 671B         |                                                   |                                               |            |
| New                                 | ![Kimi](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/moonshotai_new.png) | moonshotai/Kimi-K2-Instruct                     | Kimi            | ￥         | 16         | / M Tokens          | 💰🎁         | Kimi K2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型 | 对话           | Tools        | MoE          | 1T           | 128K         |                                                   |                                               |            |
| New                                 | ![Kimi](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/moonshotai_new.png) | Pro/moonshotai/Kimi-K2-Instruct                 | Kimi            | ￥         | 16         | / M Tokens          | 💰          | Kimi K2 是一款具备超强代码和 Agent 能力的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型 | 对话           | Tools        | MoE          | 1T           | 128K         |                                                   |                                               |            |
| New                                 | ![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml) | THUDM/GLM-4.1V-9B-Thinking                      | 智谱 AI         |            |            |                     |            | GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。作为一个 9B 参数规模的轻量级模型，它在部署效率和性能之间取得了平衡，在 28 项权威评测基准中，有 18 项的表现持平甚至超越了 72B 参数规模的 Qwen-2.5-VL-72B。该模型不仅在图文理解、数学科学推理、视频理解等任务上表现卓越，还支持高达 4K 分辨率的图像和任意宽高比输入 | 对话           | 视觉         | 9B           | 64K          |              | 免费                                              |                                               |            |
| New                                 | ![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml) | Pro/THUDM/GLM-4.1V-9B-Thinking                  | 智谱 AI         | ￥         | 1          | / M Tokens          | 💰🎁         | GLM-4.1V-9B-Thinking 是由智谱 AI 和清华大学 KEG 实验室联合发布的一款开源视觉语言模型（VLM），专为处理复杂的多模态认知任务而设计。该模型基于 GLM-4-9B-0414 基础模型，通过引入“思维链”（Chain-of-Thought）推理机制和采用强化学习策略，显著提升了其跨模态的推理能力和稳定性。作为一个 9B 参数规模的轻量级模型，它在部署效率和性能之间取得了平衡，在 28 项权威评测基准中，有 18 项的表现持平甚至超越了 72B 参数规模的 Qwen-2.5-VL-72B。该模型不仅在图文理解、数学科学推理、视频理解等任务上表现卓越，还支持高达 4K 分辨率的图像和任意宽高比输入 | 对话           | 视觉         | 9B           | 64K          |              |                                                   |                                               |            |
| New                                 | ![百度](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/baidu.svg+xml) | baidu/ERNIE-4.5-300B-A47B                       | 百度            | ￥         | 8          | / M Tokens          | 💰🎁         | ERNIE-4.5-300B-A47B 是由百度公司开发的一款基于混合专家（MoE）架构的大语言模型。该模型总参数量为 3000 亿，但在推理时每个 token 仅激活 470 亿参数，从而在保证强大性能的同时兼顾了计算效率。作为 ERNIE 4.5 系列的核心模型之一，在文本理解、生成、推理和编程等任务上展现出卓越的能力。该模型采用了一种创新的多模态异构 MoE 预训练方法，通过文本与视觉模态的联合训练，有效提升了模型的综合能力，尤其在指令遵循和世界知识记忆方面效果突出。百度已将该模型连同系列内其他模型一同开源，旨在推动 AI 技术的研发与应用 | 对话           | MoE          | 300B         | 128K         |              |                                                   |                                               |            |
| New                                 | ![腾讯混元](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/hunyuan.svg+xml) | tencent/Hunyuan-A13B-Instruct                   | 腾讯混元        | ￥         | 4          | / M Tokens          | 💰🎁         | Hunyuan-A13B-Instruct 参数量800 亿，激活 130 亿参数即可对标更大模型，支持“快思考/慢思考”混合推理；长文理解稳定；经 BFCL-v3 与 τ-Bench 验证，Agent 能力领先；结合 GQA 与多量化格式，实现高效推理。 | 对话           | 推理模型     | MoE          | 80B          | 128K         |                                                   |                                               |            |
| New                                 | ![Kimi](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/moonshotai_new.png) | moonshotai/Kimi-Dev-72B                         | Kimi            | ￥         | 8          | / M Tokens          | 💰🎁         | Kimi-Dev-72B 是新一代开源编程大模型，在 SWE-bench Verified 上取得 60.4% 的领先成绩。通过大规模强化学习优化，能在真实 Docker 环境中自动修复代码，仅在通过完整测试集时获得奖励，从而保证解决方案的正确性和鲁棒性，更贴近真实软件开发标准 | 对话           | 推理模型     | 72B          | 128K         |              |                                                   |                                               |            |
| New                                 | ![MiniMax](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/minimax-color.svg+xml) | MiniMaxAI/MiniMax-M1-80k                        | MiniMax         | ￥         | 16         | / M Tokens          | 💰🎁         | MiniMax-M1 是开源权重的大规模混合注意力推理模型，拥有 4560 亿参数，每个 Token 可激活约 459 亿参数。模型原生支持 100 万 Token 的超长上下文，并通过闪电注意力机制，在 10 万 Token 的生成任务中相比 DeepSeek R1 节省 75% 的浮点运算量。同时，MiniMax-M1 采用 MoE（混合专家）架构，结合 CISPO 算法与混合注意力设计的高效强化学习训练，在长输入推理与真实软件工程场景中实现了业界领先的性能。 | 对话           | 推理模型     | MoE          | 456B         | 128K         |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Tongyi-Zhiwen/QwenLong-L1-32B                   | Qwen            | ￥         | 4          | / M Tokens          | 💰🎁         | QwenLong-L1-32B 是首个使用强化学习训练的长上下文大型推理模型（LRM），专门针对长文本推理任务进行优化。该模型通过渐进式上下文扩展的强化学习框架，实现了从短上下文到长上下文的稳定迁移。在七个长上下文文档问答基准测试中，QwenLong-L1-32B 超越了 OpenAI-o3-mini 和 Qwen3-235B-A22B 等旗舰模型，性能可媲美 Claude-3.7-Sonnet-Thinking。该模型特别擅长数学推理、逻辑推理和多跳推理等复杂任务 | 对话           | FIM          | 推理模型     | 32B          | 128K         |                                                   |                                               |            |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~deepseek-ai/DeepSeek-R1-0528-Qwen3-8B~~       | ~~DeepSeek~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~DeepSeek-R1-0528-Qwen3-8B 是通过从 DeepSeek-R1-0528 模型蒸馏思维链到 Qwen3 8B Base 获得的模型。该模型在开源模型中达到了最先进（SOTA）的性能，在 AIME 2024 测试中超越了 Qwen3 8B 10%，并达到了 Qwen3-235B-thinking 的性能水平。该模型在数学推理、编程和通用逻辑等多个基准测试中表现出色，其架构与 Qwen3-8B 相同，但共享 DeepSeek-R1-0528 的分词器配置~~ | ~~对话~~       | ~~推理模型~~ | ~~8B~~       | ~~128K~~     | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-30B-A3B                              | Qwen            | ￥         | 2.8        | / M Tokens          | 💰🎁         | Qwen3-30B-A3B 是通义千问系列的最新大语言模型，采用混合专家（MoE）架构，拥有 30.5B 总参数量和 3.3B 激活参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力 | 对话           | Tools        | 推理模型     | MoE          | 30B          |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-32B                                  | Qwen            | ￥         | 4          | / M Tokens          | 💰🎁         | Qwen3-32B 是通义千问系列的最新大语言模型，拥有 32.8B 参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力 | 对话           | Tools        | 推理模型     | 32B          | 128K         |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-14B                                  | Qwen            | ￥         | 2          | / M Tokens          | 💰🎁         | Qwen3-14B 是通义千问系列的最新大语言模型，拥有 14.8B 参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力 | 对话           | Tools        | 推理模型     | 14B          | 128K         |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-8B                                   | Qwen            |            |            |                     |            | Qwen3-8B 是通义千问系列的最新大语言模型，拥有 8.2B 参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力 | 对话           | Tools        | 推理模型     | 8B           | 128K         | 免费                                              |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Reranker-8B                          | Qwen            | ￥         | 0.28       | / M Tokens          | 💰🎁         | Qwen3-Reranker-8B 是 Qwen3 系列中拥有 80 亿参数的文本重排模型。 它的设计目标是通过根据查询对文档的相关性进行精确重排，从而优化并提升搜索结果的质量。 该模型构建于强大的 Qwen3 基础模型之上，擅长理解长文本（支持 32k 上下文长度），并支持超过 100 种语言。 Qwen3-Reranker-8B 作为其灵活系列的一员，在多种文本和代码检索场景中展现了顶尖的性能 | 重排序         | 32K          |              |              |              |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Embedding-8B                         | Qwen            | ￥         | 0.28       | / M Tokens          | 💰🎁         | Qwen3-Embedding-8B 是 Qwen3 嵌入模型系列的最新专有模型，专为文本嵌入和排序任务设计。该模型基于 Qwen3 系列的密集基础模型，具有 80 亿参数规模，支持长达 32K 的上下文长度，可生成最高 4096 维的嵌入向量。该模型继承了基础模型卓越的多语言能力，支持超过 100 种语言，具备长文本理解和推理能力。在 MTEB 多语言排行榜上排名第一（截至 2025 年 6 月 5 日，得分 70.58），在文本检索、代码检索、文本分类、文本聚类和双语挖掘等多项任务中表现出色。模型支持用户自定义输出维度（32 到 4096）和指令感知功能，可根据特定任务、语言或场景进行优化 | 嵌入           | 4096 维      | 32K          |              |              |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Reranker-4B                          | Qwen            | ￥         | 0.14       | / M Tokens          | 💰🎁         | Qwen3-Reranker-4B 是一款功能强大的文本重排模型，源自 Qwen3 系列，拥有 40 亿参数。 该模型旨在通过根据查询对初始文档列表进行重新排序，从而显著提升搜索结果的相关性。 它继承了其 Qwen3 基础模型的核心优势，包括对长文本（上下文长度高达 32k）的卓越理解能力以及对超过 100 种语言的强大支持。 基准测试结果表明，Qwen3-Reranker-4B 模型在各种文本和代码检索评测中表现出色 | 重排序         | 32K          |              |              |              |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Embedding-4B                         | Qwen            | ￥         | 0.14       | / M Tokens          | 💰🎁         | Qwen3-Embedding-4B 是 Qwen3 嵌入模型系列的最新专有模型，专为文本嵌入和排序任务设计。该模型基于 Qwen3 系列的密集基础模型，具有 40 亿参数规模，支持长达 32K 的上下文长度，可生成最高 2560 维的嵌入向量。模型继承了基础模型卓越的多语言能力，支持超过 100 种语言，具备长文本理解和推理能力。在 MTEB 多语言排行榜上表现卓越（得分 69.45），在文本检索、代码检索、文本分类、文本聚类和双语挖掘等多项任务中表现出色。模型支持用户自定义输出维度（32 到 2560）和指令感知功能，可根据特定任务、语言或场景进行优化，在效率和效果之间达到良好平衡 | 嵌入           | 2048 维      | 32K          |              |              |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Reranker-0.6B                        | Qwen            | ￥         | 0.07       | / M Tokens          | 💰🎁         | Qwen3-Reranker-0.6B 是一款来自 Qwen3 系列的文本重排模型。 它专为优化初始检索系统的结果而设计，其核心功能是根据给定查询对文档的相关性进行重新排序。 该模型拥有 6 亿参数和 32k 的上下文长度，并继承了其 Qwen3 基础模型强大的多语言（支持超过 100 种语言）、长文本理解及推理能力。评测结果显示，Qwen3-Reranker-0.6B 在 MTEB-R、CMTEB-R 和 MLDR 等多个文本检索基准测试中均取得了优异的性能 | 重排序         | 32K          |              |              |              |                                                   |                                               |            |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-Embedding-0.6B                       | Qwen            | ￥         | 0.07       | / M Tokens          | 💰🎁         | Qwen3-Embedding-0.6B 是 Qwen3 嵌入模型系列的最新专有模型，专为文本嵌入和排序任务设计。该模型基于 Qwen3 系列的密集基础模型，具有 6 亿参数规模，支持长达 32K 的上下文长度，可生成最高 1024 维的嵌入向量。模型继承了基础模型卓越的多语言能力，支持超过 100 种语言，具备长文本理解和推理能力。在 MTEB 多语言排行榜上表现优异（得分 64.33），在文本检索、代码检索、文本分类、文本聚类和双语挖掘等多项任务中表现出色。模型支持用户自定义输出维度（32 到 1024）和指令感知功能，可根据特定任务、语言或场景进行优化，为需要平衡效率和效果的应用场景提供理想选择 | 嵌入           | 1024 维      | 32K          |              |              |                                                   |                                               |            |
| New                                 | ![ascend-tribe](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/ascend_tribe.svg+xml) | ascend-tribe/pangu-pro-moe                      | ascend-tribe    | ￥         | 4          | / M Tokens          | 💰🎁         | Pangu-Pro-MoE 72B-A16B 是一款 720 亿参数、激活 160 亿参的稀疏大语言模型，它基于分组混合专家（MoGE）架构，它在专家选择阶段对专家进行分组，并约束 token 在每个组内激活等量专家，从而实现专家负载均衡，显著提升模型在昇腾平台的部署效率 | 对话           | 推理模型     | MoE          | 72B          | 128k         |                                                   |                                               |            |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/GLM-Z1-32B-0414~~                       | ~~智谱 AI~~     | ~~￥~~     | ~~4~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~GLM-Z1-32B-0414 是一个具有深度思考能力的推理模型。该模型基于 GLM-4-32B-0414 通过冷启动和扩展强化学习开发，并在数学、代码和逻辑任务上进行了进一步训练。与基础模型相比，GLM-Z1-32B-0414 显著提升了数学能力和解决复杂任务的能力。在训练过程中，研究团队还引入了基于成对排序反馈的通用强化学习，进一步增强了模型的通用能力。虽然只有 32B 参数，但在部分任务上，其性能已能与拥有 671B 参数的 DeepSeek-R1 相媲美。通过在 AIME 24/25、LiveCodeBench、GPQA 等基准测试中的评估，该模型展现了较强的数理推理能力，能够支持解决更广泛复杂任务~~ | ~~对话~~       | ~~Tools~~    | ~~32B~~      | ~~128K~~     | ~~推理模型~~ | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/GLM-4-32B-0414~~                        | ~~智谱 AI~~     | ~~￥~~     | ~~1.89~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~GLM-4-32B-0414 是 GLM 系列的新一代开源模型，拥有 320 亿参数。该模型性能可与 OpenAI 的 GPT 系列和 DeepSeek 的 V3/R1 系列相媲美，并支持非常用户友好的本地部署功能。GLM-4-32B-Base-0414 是在 15T 高质量数据上预训练的，包括大量推理类型的合成数据，为后续的强化学习扩展奠定了基础。在后训练阶段，除了对话场景的人类偏好对齐外，研究团队还使用拒绝采样和强化学习等技术增强了模型在指令遵循、工程代码和函数调用方面的表现，加强了代理任务所需的原子能力。GLM-4-32B-0414 在工程代码、Artifact 生成、函数调用、基于搜索的问答和报告生成等领域取得了良好的成果，部分 Benchmark 指标已接近甚至超越 GPT-4o、DeepSeek-V3-0324（671B）等更大模型的水平~~ | ~~对话~~       | ~~Tools~~    | ~~32B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/GLM-Z1-9B-0414~~                        | ~~智谱 AI~~     | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~GLM-Z1-9B-0414 是 GLM 系列的小型模型，仅有 90 亿参数，但保持了开源传统的同时展现出惊人的能力。尽管规模较小，该模型在数学推理和通用任务上仍表现出色，其总体性能在同等规模的开源模型中已处于领先水平。研究团队采用了与大模型相同的一系列技术进行训练，使其在资源受限的场景中能够实现效率与效果的绝佳平衡，为寻求轻量级部署的用户提供强大选择。特别是在资源受限的场景下，该模型可以很好地在效率与效果之间取得平衡，为需要轻量化部署的用户提供强有力的选择~~ | ~~对话~~       | ~~Tools~~    | ~~9B~~       | ~~128K~~     | ~~推理模型~~ | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/GLM-4-9B-0414~~                         | ~~智谱 AI~~     | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~GLM-4-9B-0414 是 GLM 系列的小型模型，拥有 90 亿参数。该模型继承了 GLM-4-32B 系列的技术特点，但提供了更轻量级的部署选择。尽管规模较小，GLM-4-9B-0414 仍在代码生成、网页设计、SVG 图形生成和基于搜索的写作等任务上展现出色能力。该模型还支持函数调用功能，可以调用外部工具以扩展其能力范围。模型在资源受限的场景中表现出良好的效率与效果平衡，为需要在计算资源有限条件下部署 AI 模型的用户提供了强大选择。与其他同系列模型一样，GLM-4-9B-0414 也展示了在各种基准测试中的竞争性能力~~ | ~~对话~~       | ~~Tools~~    | ~~9B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-VL-32B-Instruct~~                | ~~Qwen~~        | ~~￥~~     | ~~1.89~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-VL-32B-Instruct 是通义千问团队推出的多模态大模型，是 Qwen2.5-VL 系列的一部分。该模型不仅精通识别常见物体，还能分析图像中的文本、图表、图标、图形和布局。它可作为视觉智能体，能够推理并动态操控工具，具备使用电脑和手机的能力。此外，这个模型可以精确定位图像中的对象，并为发票、表格等生成结构化输出。相比前代模型 Qwen2-VL，该版本在数学和问题解决能力方面通过强化学习得到了进一步提升，响应风格也更符合人类偏好~~ | ~~对话~~       | ~~视觉~~     | ~~32B~~      | ~~128K~~     | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Wan](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Wan-AI/Wan2.1-I2V-14B-720P-Turbo~~            | ~~Wan~~         | ~~￥~~     | ~~1.5~~    | ~~/ Video~~         | ~~💰🎁~~     | ~~Wan2.1-I2V-14B-720P-Turbo 是 Wan2.1-I2V-14B-720P 模型的 TeaCache 加速版，单个视频生成时间压缩 30%。Wan2.1-I2V-14B-720P 是一个开源的高级图像到视频生成模型，是 Wan2.1 视频基础模型套件的一部分。该 14B 模型能够生成 720P 高清视频，经过数千轮人工评估，达到了先进性能水平。它采用扩散变换器架构，并通过创新的时空变分自编码器（VAE）、可扩展的训练策略和大规模数据构建来提升生成能力。该模型还能够理解和处理中、英文文本，为视频生成任务提供了强大支持~~ | ~~视频~~       | ~~14B~~      | ~~图生视频~~ | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Wan](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Wan-AI/Wan2.1-I2V-14B-720P~~                  | ~~Wan~~         | ~~￥~~     | ~~2~~      | ~~/ Video~~         | ~~💰🎁~~     | ~~Wan2.1-I2V-14B-720P 是一个开源的高级图像到视频生成模型，是 Wan2.1 视频基础模型套件的一部分。该 14B 模型能够生成 720P 高清视频，经过数千轮人工评估，达到先进性能水平。它采用扩散变换器架构，并通过创新的时空变分自编码器（VAE）、可扩展的训练策略和大规模数据构建来提升生成能力。该模型还能够理解和处理中、英文文本，为视频生成任务提供了强大支持~~ | ~~视频~~       | ~~14B~~      | ~~图生视频~~ | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Wan](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Wan-AI/Wan2.1-T2V-14B-Turbo~~                 | ~~Wan~~         | ~~￥~~     | ~~1.5~~    | ~~/ Video~~         | ~~💰🎁~~     | ~~Wan2.1-T2V-14B-T 是 Wan2.1-T2V-14B 模型的 TeaCache 加速版，单个视频生成时间压缩 30%。Wan2.1-T2V-14B 模型在开源和闭源模型中均创造了最先进的性能基准，能够生成具有显著动态效果的高质量视觉内容。它是唯一一个能够同时生成中英文文本的视频模型，并支持 480P 和 720P 分辨率的视频生成。模型采用扩散变换器架构，并通过创新的时空变分自编码器（VAE）、可扩展的训练策略和大规模数据构建来提升生成能力~~ | ~~视频~~       | ~~14B~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Wan](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Wan-AI/Wan2.1-T2V-14B~~                       | ~~Wan~~         | ~~￥~~     | ~~2~~      | ~~/ Video~~         | ~~💰🎁~~     | ~~Wan2.1-T2V-14B 是一个开源的高级文本到视频生成模型，该 14B 模型在开源和闭源模型中均创造了最先进的性能基准，能够生成具有显著动态效果的高质量视觉内容。它是唯一一个能够同时生成中英文文本的视频模型，并支持 480P 和 720P 分辨率的视频生成。模型采用扩散变换器架构，并通过创新的时空变分自编码器（VAE）、可扩展的训练策略和大规模数据构建来提升生成能力~~ | ~~视频~~       | ~~14B~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| New                                 | ![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml) | Qwen/Qwen3-235B-A22B                            | Qwen            | ￥         | 10         | / M Tokens          | 💰🎁         | Qwen3-235B-A22B 是通义千问系列的最新大语言模型，采用混合专家（MoE）架构，拥有 235B 总参数量和 22B 激活参数量。该模型独特地支持在思考模式（适用于复杂逻辑推理、数学和编程）和非思考模式（适用于高效的通用对话）之间无缝切换，显著增强了推理能力。模型在数学、代码生成和常识逻辑推理上表现优异，并在创意写作、角色扮演和多轮对话等方面展现出卓越的人类偏好对齐能力。此外，该模型支持 100 多种语言和方言，具备出色的多语言指令遵循和翻译能力 | 对话           | Tools        | 推理模型     | MoE          | 235B         |                                                   |                                               |            |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/QwQ-32B~~                                | ~~Qwen~~        | ~~￥~~     | ~~4~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~QwQ 是 Qwen 系列的推理模型。与传统的指令调优模型相比，QwQ 具备思考和推理能力，能够在下游任务中实现显著增强的性能，尤其是在解决困难问题方面。QwQ-32B 是中型推理模型，能够在与最先进的推理模型（如 DeepSeek-R1、o1-mini）的对比中取得有竞争力的性能。该模型采用 RoPE、SwiGLU、RMSNorm 和 Attention QKV bias 等技术，具有 64 层网络结构和 40 个 Q 注意力头（GQA 架构中 KV 为 8 个）~~ | ~~对话~~       | ~~Tools~~    | ~~推理模型~~ | ~~32B~~      | ~~128K~~     | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-VL-72B-Instruct~~                | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-VL 是 Qwen2.5 系列中的视觉语言模型。该模型在多方面有显著提升：具备更强的视觉理解能力，能够识别常见物体、分析文本、图表和布局；作为视觉代理能够推理并动态指导工具使用；支持理解超过 1 小时的长视频并捕捉关键事件；能够通过生成边界框或点准确定位图像中的物体；支持生成结构化输出，尤其适用于发票、表格等扫描数据。模型在多项基准测试中表现出色，包括图像、视频和代理任务评测~~ | ~~对话~~       | ~~视觉~~     | ~~72B~~      | ~~128K~~     | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Pro/Qwen/Qwen2.5-VL-7B-Instruct~~             | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-VL 是 Qwen 系列的新成员，具备强大的视觉理解能力，能分析图像中的文本、图表和布局，并能理解长视频和捕捉事件，它可以进行推理、操作工具，支持多格式物体定位和生成结构化输出，优化了视频理解的动态分辨率与帧率训练，并提升了视觉编码器效率。~~ | ~~对话~~       | ~~视觉~~     | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~deepseek-ai/DeepSeek-R1-Distill-Qwen-32B~~    | ~~DeepSeek~~    | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-R1-Distill-Qwen-32B 是基于 Qwen2.5-32B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在数学、编程和推理等多个领域展现出卓越的性能。在 AIME 2024、MATH-500、GPQA Diamond 等多个基准测试中都取得了优异成绩，其中在 MATH-500 上达到了 94.3% 的准确率，展现出强大的数学推理能力~~ | ~~对话~~       | ~~Tools~~    | ~~推理模型~~ | ~~32B~~      | ~~128K~~     | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~deepseek-ai/DeepSeek-R1-Distill-Qwen-14B~~    | ~~DeepSeek~~    | ~~￥~~     | ~~0.7~~    | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-R1-Distill-Qwen-14B 是基于 Qwen2.5-14B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 93.9% 的准确率，在 AIME 2024 上达到了 69.7% 的通过率，在 CodeForces 上获得了 1481 的评分，显示出在数学和编程领域的强大实力~~ | ~~对话~~       | ~~Tools~~    | ~~推理模型~~ | ~~14B~~      | ~~128K~~     | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~deepseek-ai/DeepSeek-R1-Distill-Qwen-7B~~     | ~~DeepSeek~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力~~ | ~~对话~~       | ~~Tools~~    | ~~推理模型~~ | ~~7B~~       | ~~128K~~     | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/QVQ-72B-Preview~~                        | ~~Qwen~~        | ~~￥~~     | ~~9.9~~    | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~QVQ-72B-Preview 是由 Qwen 团队开发的专注于视觉推理能力的研究型模型。该模型在多项基准测试中表现突出，在 MMMU 测试中达到了 70.3% 的卓越成绩，在 MathVista 达到 71.4% 的优异表现，展现了其在多学科理解和数学视觉推理方面的卓越能力。作为专门针对视觉推理优化的模型，QVQ-72B-Preview 在复杂场景理解和解决视觉相关的数学问题方面具有独特优势~~ | ~~对话~~       | ~~视觉~~     | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| 1210                                | ![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml) | deepseek-ai/DeepSeek-V2.5                       | DeepSeek        | ￥         | 1.33       | / M Tokens          | 💰🎁         | DeepSeek-V2.5-1210 是 DeepSeek-V2.5 的升级版本，在多个能力方面都有显著提升。在数学能力方面，其在 MATH-500 基准测试上的表现从 74.8% 提升至 82.8%；在编程方面，LiveCodebench 基准测试的准确率从 29.2% 提升至 34.38%。同时在写作和推理方面也有明显改进。模型支持函数调用、JSON 输出和填充式补全等多种功能 | 对话           | FIM          | Tools        | MoE          | 236B         |                                                   |                                               |            |
| ~~&nbsp;~~                          | ~~![腾讯混元](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/hunyuan.svg+xml)~~ | ~~tencent/HunyuanVideo-HD~~                     | ~~腾讯混元~~    | ~~￥~~     | ~~2.8~~    | ~~/ Video~~         | ~~💰🎁~~     | ~~HunyuanVideo 是腾讯推出的开源视频生成基础模型，拥有超过 130 亿参数，是目前最大的开源视频生成模型。该模型采用统一的图像和视频生成架构，集成了数据整理、图像-视频联合模型训练和高效基础设施等关键技术。模型使用多模态大语言模型作为文本编码器，通过 3D VAE 进行空间-时间压缩，并提供提示词重写功能。根据专业人工评估结果，HunyuanVideo 在文本对齐、运动质量和视觉质量等方面的表现优于现有最先进的模型~~ | ~~视频~~       | ~~13B~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![FunAudioLLM](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/FunAudioLLM.png)~~ | ~~FunAudioLLM/CosyVoice2-0.5B~~                 | ~~FunAudioLLM~~ | ~~￥~~     | ~~50~~     | ~~/ M UTF-8 bytes~~ | ~~💰🎁~~     | ~~CosyVoice 2 是一个基于大语言模型的流式语音合成模型，采用统一的流式/非流式框架设计。该模型通过有限标量量化（FSQ）来提升语音 token 的编码本利用率，简化了文本到语音的语言模型架构，并开发了支持不同合成场景的分块感知因果流匹配模型。在流式模式下，模型可实现 150ms 的超低延迟，同时保持与非流式模式几乎相同的合成质量。相比 1.0 版本，发音错误率降低了 30%-50%，MOS 评分从 5.4 提升至 5.53，并支持情感和方言的细粒度控制。支持中文（含方言：粤语、四川话、上海话、天津话等）、英文、日语、韩语，支持跨语言和混合语言场景~~ | ~~语音~~       | ~~多语言~~   | ~~0.5B~~     | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![FunAudioLLM](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/FunAudioLLM.png)~~ | ~~FunAudioLLM/SenseVoiceSmall~~                 | ~~FunAudioLLM~~ | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~SenseVoice 是一个具有多种语音理解能力的语音基础模型，包括自动语音识别（ASR）、口语语言识别（LID）、语音情感识别（SER）和音频事件检测（AED）。SenseVoice-Small 模型采用非自回归端到端框架，具有非常低的推理延迟。它支持 50 多种语言的多语言语音识别，在中文和粤语识别方面表现优于 Whisper 模型。此外，它还具有出色的情感识别和音频事件检测能力。该模型处理 10 秒音频仅需 70 毫秒，比 Whisper-Large 快 15 倍~~ | ~~语音~~       | ~~多语言~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~BAAI/bge-m3~~                                 | ~~智源研究院~~  | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~BGE-M3 是一个多功能、多语言、多粒度的文本嵌入模型。它支持三种常见的检索功能：密集检索、多向量检索和稀疏检索。该模型可以处理超过100种语言，并且能够处理从短句到长达8192个词元的长文档等不同粒度的输入。BGE-M3在多语言和跨语言检索任务中表现出色，在 MIRACL 和 MKQA 等基准测试中取得了领先结果。它还具有处理长文档检索的能力，在 MLDR 和 NarritiveQA 等数据集上展现了优秀性能~~ | ~~嵌入~~       | ~~多语言~~   | ~~1024 维~~  | ~~8K~~       | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~BAAI/bge-reranker-v2-m3~~                     | ~~智源研究院~~  | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~BAAI/bge-reranker-v2-m3 是一个轻量级的多语言重排序模型。它基于 bge-m3 模型开发，具有强大的多语言能力，易于部署，并且推理速度快。该模型采用查询和文档作为输入，直接输出相似度分数，而不是嵌入向量。它适用于多语言场景，特别是在中文和英文处理方面表现出色~~ | ~~重排序~~     | ~~多语言~~   | ~~568M~~     | ~~8K~~       | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![网易有道](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/netease-youdao.svg+xml)~~ | ~~netease-youdao/bce-embedding-base_v1~~        | ~~网易有道~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~bce-embedding-base_v1 是由网易有道开发的双语和跨语言嵌入模型。该模型在中英文语义表示和检索任务中表现出色，尤其擅长跨语言场景。它是为检索增强生成（RAG）系统优化的，可以直接应用于教育、医疗、法律等多个领域。该模型不需要特定指令即可使用，能够高效地生成语义向量，为语义搜索和问答系统提供关键支持~~ | ~~嵌入~~       | ~~多语言~~   | ~~768 维~~   | ~~279M~~     | ~~512~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![网易有道](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/netease-youdao.svg+xml)~~ | ~~netease-youdao/bce-reranker-base_v1~~         | ~~网易有道~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~bce-reranker-base_v1 是网易有道开发的双语和跨语言重排序模型，支持中文、英文、日文和韩文。该模型在 RAG 系统中用于精确重排检索结果，可以提供有意义的相关性分数，有助于过滤低质量段落。它针对多种 RAG 任务进行了优化，包括翻译、摘要和问答等。该模型无需特定指令即可使用，具有广泛的领域适应性，已在有道的多个产品中得到验证~~ | ~~重排序~~     | ~~多语言~~   | ~~279M~~     | ~~512~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-Coder-32B-Instruct~~             | ~~Qwen~~        | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-Coder-32B-Instruct 是基于 Qwen2.5 开发的代码特定大语言模型。该模型通过 5.5 万亿 tokens 的训练，在代码生成、代码推理和代码修复方面都取得了显著提升。它是当前最先进的开源代码语言模型，编码能力可与 GPT-4 相媲美。模型不仅增强了编码能力，还保持了在数学和通用能力方面的优势，并支持长文本处理~~ | ~~对话~~       | ~~FIM~~      | ~~Tools~~    | ~~Coder~~    | ~~32B~~      | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![可图](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/20250227-194559.png)~~ | ~~Kwai-Kolors/Kolors~~                          | ~~可图~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Kolors 是由快手 Kolors 团队开发的基于潜在扩散的大规模文本到图像生成模型。该模型通过数十亿文本-图像对的训练，在视觉质量、复杂语义准确性以及中英文字符渲染方面展现出显著优势。它不仅支持中英文输入，在理解和生成中文特定内容方面也表现出色~~ | ~~生图~~       | ~~图生图~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2-VL-72B-Instruct~~                  | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等~~ | ~~对话~~       | ~~视觉~~     | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-72B-Instruct-128K~~              | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的上下文。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~72B~~      | ~~128K~~     | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~deepseek-ai/deepseek-vl2~~                    | ~~DeepSeek~~    | ~~￥~~     | ~~0.99~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-VL2 是一个基于 DeepSeekMoE-27B 开发的混合专家（MoE）视觉语言模型，采用稀疏激活的 MoE 架构，在仅激活 4.5B 参数的情况下实现了卓越性能。该模型在视觉问答、光学字符识别、文档/表格/图表理解和视觉定位等多个任务中表现优异，与现有的开源稠密模型和基于 MoE 的模型相比，在使用相同或更少的激活参数的情况下，实现了具有竞争力的或最先进的性能表现~~ | ~~对话~~       | ~~视觉~~     | ~~MoE~~      | ~~27B~~      | ~~4K~~       | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-72B-Instruct~~                   | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-32B-Instruct~~                   | ~~Qwen~~        | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~32B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-14B-Instruct~~                   | ~~Qwen~~        | ~~￥~~     | ~~0.7~~    | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~14B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-7B-Instruct~~                    | ~~Qwen~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~Free~~     | ~~7B~~       | ~~32K~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2.5-Coder-7B-Instruct~~              | ~~Qwen~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础~~ | ~~对话~~       | ~~FIM~~      | ~~Coder~~    | ~~7B~~       | ~~32K~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![书生·浦语](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/internlm.svg+xml)~~ | ~~internlm/internlm2_5-7b-chat~~                | ~~书生·浦语~~   | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域~~ | ~~对话~~       | ~~Tools~~    | ~~Free~~     | ~~7B~~       | ~~32K~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Qwen/Qwen2-7B-Instruct~~                      | ~~Qwen~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升~~ | ~~对话~~       | ~~Free~~     | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/glm-4-9b-chat~~                         | ~~智谱 AI~~     | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用~~ | ~~对话~~       | ~~Tools~~    | ~~Free~~     | ~~9B~~       | ~~128K~~     | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~BAAI/bge-large-zh-v1.5~~                      | ~~智源研究院~~  | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~BAAI/bge-large-zh-v1.5 是一个大型中文文本嵌入模型，是 BGE (BAAI General Embedding) 系列的一部分。该模型在 C-MTEB 基准测试中表现出色，在 31 个数据集上的平均得分为 64.53，在检索、语义相似度、文本对分类等多个任务中都取得了优异成绩。它支持最大 512 个 token 的输入长度，适用于各种中文自然语言处理任务，如文本检索、语义相似度计算等~~ | ~~嵌入~~       | ~~中文~~     | ~~1024 维~~  | ~~335M~~     | ~~512~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~BAAI/bge-large-en-v1.5~~                      | ~~智源研究院~~  | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~BAAI/bge-large-en-v1.5 是一个大型英文文本嵌入模型，是 BGE (BAAI General Embedding) 系列的一部分。它在 MTEB 基准测试中取得了优异的表现，在 56 个数据集上的平均得分为 64.23，在检索、聚类、文本对分类等多个任务中表现出色。该模型支持最大 512 个 token 的输入长度，适用于各种自然语言处理任务，如文本检索、语义相似度计算等~~ | ~~嵌入~~       | ~~英文~~     | ~~1024 维~~  | ~~335M~~     | ~~512~~      | ~~免费~~                                          | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B~~ | ~~DeepSeek~~    | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-R1-Distill-Qwen-7B 是基于 Qwen2.5-Math-7B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，展现出优秀的推理能力。在多个基准测试中表现出色，其中在 MATH-500 上达到了 92.8% 的准确率，在 AIME 2024 上达到了 55.5% 的通过率，在 CodeForces 上获得了 1189 的评分，作为 7B 规模的模型展示了较强的数学和编程能力~~ | ~~对话~~       | ~~Tools~~    | ~~推理模型~~ | ~~7B~~       | ~~128K~~     | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Pro/Qwen/Qwen2.5-Coder-7B-Instruct~~          | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础~~ | ~~对话~~       | ~~FIM~~      | ~~Coder~~    | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~Pro/BAAI/bge-m3~~                             | ~~智源研究院~~  | ~~￥~~     | ~~0.07~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~BGE-M3 是一个多功能、多语言、多粒度的文本嵌入模型。它支持三种常见的检索功能：密集检索、多向量检索和稀疏检索。该模型可以处理超过100种语言，并且能够处理从短句到长达8192个词元的长文档等不同粒度的输入。BGE-M3在多语言和跨语言检索任务中表现出色，在 MIRACL 和 MKQA 等基准测试中取得了领先结果。它还具有处理长文档检索的能力，在 MLDR 和 NarritiveQA 等数据集上展现了优秀性能~~ | ~~嵌入~~       | ~~多语言~~   | ~~1024 维~~  | ~~8K~~       | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智源研究院](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/BAAI.svg+xml)~~ | ~~Pro/BAAI/bge-reranker-v2-m3~~                 | ~~智源研究院~~  | ~~￥~~     | ~~0.07~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~BAAI/bge-reranker-v2-m3 是一个轻量级的多语言重排序模型。它基于 bge-m3 模型开发，具有强大的多语言能力，易于部署，并且推理速度快。该模型采用查询和文档作为输入，直接输出相似度分数，而不是嵌入向量。它适用于多语言场景，特别是在中文和英文处理方面表现出色~~ | ~~重排序~~     | ~~多语言~~   | ~~568M~~     | ~~8K~~       | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Pro/Qwen/Qwen2.5-7B-Instruct~~                | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~对话~~       | ~~Tools~~    | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~Pro/Qwen/Qwen2-7B-Instruct~~                  | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升~~ | ~~对话~~       | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~Pro/THUDM/glm-4-9b-chat~~                     | ~~智谱 AI~~     | ~~￥~~     | ~~0.6~~    | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用~~ | ~~对话~~       | ~~Tools~~    | ~~9B~~       | ~~128K~~     | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~THUDM/GLM-Z1-Rumination-32B-0414~~            | ~~智谱 AI~~     | ~~￥~~     | ~~4~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~GLM-Z1-Rumination-32B-0414 是一个具有沉思能力的深度推理模型（与 OpenAI 的 Deep Research 对标）。与典型的深度思考模型不同，沉思模型采用更长时间的深度思考来解决更开放和复杂的问题（例如，撰写关于两个城市 AI 发展的比较分析及其未来发展计划）。该模型在深度思考过程中集成了搜索工具以处理复杂任务，并通过利用多种基于规则的奖励来指导和扩展端到端强化学习进行训练。Z1-Rumination 在研究风格的写作和复杂检索任务上显示出显著的改进。该模型支持“自主提出问题—搜索信息—构建分析—完成任务”的完整研究闭环，默认支持搜索、点击、打开和完成等函数调用功能，使其能够更好地处理需要外部信息的复杂问题~~ | ~~对话~~       | ~~32B~~      | ~~128K~~     | ~~推理模型~~ | ~~&nbsp;~~   | ~~&nbsp;~~                                        | ~~&nbsp;~~                                    | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![电信](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Property%201%253D5G.svg+xml)~~ | ~~&nbsp;~~                                      | ~~电信~~        | ~~￥~~     | ~~1.33~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~TeleMM多模态大模型是由中国电信自主研发的多模态理解大模型，能够处理文本、图像等多种模态输入，支持图像理解、图表分析等功能，为用户提供跨模态的理解服务。模型能够与用户进行多模态交互，准确理解输入内容，回答问题、协助创作，并高效提供多模态信息和灵感支持。在细粒度感知，逻辑推理等多模态任务上有出色表现~~ | ~~Deprecated~~ | ~~视觉~~     | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~TeleAI/TeleMM~~                                 | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![电信](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Property%201%253D5G.svg+xml)~~ | ~~&nbsp;~~                                      | ~~电信~~        | ~~￥~~     | ~~1.33~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~TeleChat2大模型是由中国电信从0到1自主研发的生成式语义大模型，支持百科问答、代码生成、长文生成等功能，为用户提供对话咨询服务，能够与用户进行对话互动，回答问题，协助创作，高效便捷地帮助用户获取信息、知识和灵感。模型在幻觉问题、长文生成、逻辑理解等方面均有较出色表现。~~ | ~~Deprecated~~ | ~~8K~~       | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~TeleAI/TeleChat2~~                              | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~￥~~     | ~~1.33~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-Coder-V2 是一个开源的混合专家（MoE）代码语言模型，在代码相关任务中达到了与 GPT4-Turbo 相当的性能。它是在 DeepSeek-V2 的中间检查点基础上，通过额外 6 万亿个 token 的预训练而来。该模型显著提升了编码和数学推理能力，同时保持了通用语言任务的性能。相比 DeepSeek-Coder-33B，它在各方面都有显著进步，支持的编程语言从 86 种扩展到 338 种，上下文长度从 16K 扩展到 128K。在标准基准评估中，DeepSeek-Coder-V2 在编码和数学基准测试中的表现超过了 GPT4-Turbo、Claude 3 Opus 和 Gemini 1.5 Pro 等闭源模型~~ | ~~Deprecated~~ | ~~FIM~~      | ~~Coder~~    | ~~MoE~~      | ~~236B~~     | ~~deepseek-ai/DeepSeek-Coder-V2-Instruct~~        | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-57B-A14B-Instruct 是 Qwen2 系列中的指令微调大语言模型，采用混合专家（Mixture-of-Experts）架构，总参数量为 57B，激活参数为 14B。该模型基于 Transformer 架构，使用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中，该模型表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力~~ | ~~Deprecated~~ | ~~MoE~~      | ~~57B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~Qwen/Qwen2-57B-A14B-Instruct~~                  | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~￥~~     | ~~1.33~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-V2 是一个强大、经济高效的混合专家（MoE）语言模型。它在 8.1 万亿个 token 的高质量语料库上进行了预训练，并通过监督微调（SFT）和强化学习（RL）进一步提升了模型能力。与 DeepSeek 67B 相比， DeepSeek-V2 在性能更强的同时，节省了 42.5% 的训练成本，减少了 93.3% 的 KV 缓存，并将最大生成吞吐量提高到了 5.76 倍。该模型支持 128k 的上下文长度，在标准基准测试和开放式生成评估中都表现出色~~ | ~~Deprecated~~ | ~~MoE~~      | ~~236B~~     | ~~32K~~      | ~~&nbsp;~~   | ~~deepseek-ai/DeepSeek-V2-Chat~~                  | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![腾讯混元](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/hunyuan.svg+xml)~~ | ~~&nbsp;~~                                      | ~~腾讯混元~~    | ~~￥~~     | ~~21~~     | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~混元大模型（Hunyuan-Large）是业界最大的开源 Transformer 架构 MoE 模型，拥有 3890 亿总参数量和 520 亿激活参数量。该模型采用了高质量合成数据训练、KV 缓存压缩、专家特定学习率缩放等创新技术。在 MMLU、CMMLU、数学推理等多个基准测试中都展现出优异表现~~ | ~~Deprecated~~ | ~~MoE~~      | ~~389B~~     | ~~32K~~      | ~~&nbsp;~~   | ~~Tencent/Hunyuan-A52B-Instruct~~                 | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~￥~~     | ~~8~~      | ~~/ M Tokens~~      | ~~💰~~      | ~~DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。~~ | ~~Deprecated~~ | ~~FIM~~      | ~~Tools~~    | ~~MoE~~      | ~~671B~~     | ~~Pro/deepseek-ai/DeepSeek-V3-1226~~              | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/deepseek-st.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~￥~~     | ~~16~~     | ~~/ M Tokens~~      | ~~💰~~      | ~~DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。~~ | ~~Deprecated~~ | ~~FIM~~      | ~~Tools~~    | ~~推理模型~~ | ~~MoE~~      | ~~Pro/deepseek-ai/DeepSeek-R1-0120~~              | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~QwQ-32B-Preview是Qwen 最新的实验性研究模型，专注于提升AI推理能力。通过探索语言混合、递归推理等复杂机制，主要优势包括强大的推理分析能力、数学和编程能力。与此同时，也存在语言切换问题、推理循环、安全性考虑、其他能力方面的差异。~~ | ~~Deprecated~~ | ~~32B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Qwen/QwQ-32B-Preview~~                          | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少~~ | ~~Deprecated~~ | ~~Free~~     | ~~1.5B~~     | ~~32K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~Qwen/Qwen2-1.5B-Instruct~~                  | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~￥~~     | ~~0.14~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~DeepSeek-R1-Distill-Qwen-1.5B 是基于 Qwen2.5-Math-1.5B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在多个基准测试中展现出不错的性能。作为一个轻量级模型，在 MATH-500 上达到了 83.9% 的准确率，在 AIME 2024 上达到了 28.9% 的通过率，在 CodeForces 上获得了 954 的评分，显示出超出其参数规模的推理能力~~ | ~~Deprecated~~ | ~~Tools~~    | ~~推理模型~~ | ~~1.5B~~     | ~~128K~~     | ~~Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B~~ | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![DeepSeek](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/DeepSeek.svg+xml)~~ | ~~&nbsp;~~                                      | ~~DeepSeek~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~DeepSeek-R1-Distill-Qwen-1.5B 是基于 Qwen2.5-Math-1.5B 通过知识蒸馏得到的模型。该模型使用 DeepSeek-R1 生成的 80 万个精选样本进行微调，在多个基准测试中展现出不错的性能。作为一个轻量级模型，在 MATH-500 上达到了 83.9% 的准确率，在 AIME 2024 上达到了 28.9% 的通过率，在 CodeForces 上获得了 954 的评分，显示出超出其参数规模的推理能力~~ | ~~Deprecated~~ | ~~Tools~~    | ~~推理模型~~ | ~~1.5B~~     | ~~128K~~     | ~~免费~~                                          | ~~deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B~~ | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![书生·浦语](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/internlm.svg+xml)~~ | ~~&nbsp;~~                                      | ~~书生·浦语~~   | ~~￥~~     | ~~1~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~InternLM2.5-20B-Chat 是一个开源的大规模对话模型，基于 InternLM2 架构开发。该模型拥有 200 亿参数，在数学推理方面表现出色，超越了同量级的 Llama3 和 Gemma2-27B 模型。InternLM2.5-20B-Chat 在工具调用能力方面有显著提升，支持从上百个网页收集信息进行分析推理，并具备更强的指令理解、工具选择和结果反思能力。它适用于构建复杂智能体，可进行多轮工具调用以完成复杂任务~~ | ~~Deprecated~~ | ~~Tools~~    | ~~20B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~internlm/internlm2_5-20b-chat~~                 | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~&nbsp;~~                                      | ~~智谱 AI~~     | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用~~ | ~~Deprecated~~ | ~~Free~~     | ~~6B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~THUDM/chatglm3-6b~~                         | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-VL-7B-Instruct 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够用于高质量的基于视频的问答、对话和内容创作，还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等~~ | ~~Deprecated~~ | ~~视觉~~     | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~Pro/Qwen/Qwen2-VL-7B-Instruct~~                 | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~0.14~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少~~ | ~~Deprecated~~ | ~~1.5B~~     | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Pro/Qwen/Qwen2-1.5B-Instruct~~                  | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~1~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力~~ | ~~Deprecated~~ | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Vendor-A/Qwen/Qwen2-72B-Instruct~~              | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~1~~      | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升~~ | ~~Deprecated~~ | ~~Tools~~    | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~Vendor-A/Qwen/Qwen2.5-72B-Instruct~~            | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![腾讯混元](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/hunyuan.svg+xml)~~ | ~~&nbsp;~~                                      | ~~腾讯混元~~    | ~~￥~~     | ~~0.7~~    | ~~/ Video~~         | ~~💰🎁~~     | ~~HunyuanVideo 是腾讯推出的开源视频生成基础模型，拥有超过 130 亿参数，是目前最大的开源视频生成模型。该模型采用统一的图像和视频生成架构，集成了数据整理、图像-视频联合模型训练和高效基础设施等关键技术。模型使用多模态大语言模型作为文本编码器，通过 3D VAE 进行空间-时间压缩，并提供提示词重写功能。根据专业人工评估结果，HunyuanVideo 在文本对齐、运动质量和视觉质量等方面的表现优于现有最先进的模型~~ | ~~Deprecated~~ | ~~13B~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~tencent/HunyuanVideo~~                          | ~~视频~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![零一万物](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Yi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~零一万物~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Yi-1.5-6B-Chat 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型具有 4K、16K 和 32K 的上下文长度版本，预训练总量达到 3.6T 个 token~~ | ~~Deprecated~~ | ~~Free~~     | ~~6B~~       | ~~4K~~       | ~~&nbsp;~~   | ~~免费~~                                          | ~~01-ai/Yi-1.5-6B-Chat~~                      | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![零一万物](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Yi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~零一万物~~    | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Yi-1.5-34B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在大多数基准测试中与更大的模型相当或表现更佳，具有 16K 的上下文长度~~ | ~~Deprecated~~ | ~~34B~~      | ~~16K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~01-ai/Yi-1.5-34B-Chat-16K~~                     | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![零一万物](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Yi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~零一万物~~    | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Yi-1.5-9B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在同等规模的开源模型中表现最佳~~ | ~~Deprecated~~ | ~~Free~~     | ~~9B~~       | ~~16K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~01-ai/Yi-1.5-9B-Chat-16K~~                  | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![零一万物](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Yi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~零一万物~~    | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Yi-1.5-6B-Chat 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型具有 4K、16K 和 32K 的上下文长度版本，预训练总量达到 3.6T 个 token~~ | ~~Deprecated~~ | ~~6B~~       | ~~4K~~       | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Pro/01-ai/Yi-1.5-6B-Chat~~                      | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![零一万物](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Yi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~零一万物~~    | ~~￥~~     | ~~0.42~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Yi-1.5-9B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在同等规模的开源模型中表现最佳~~ | ~~Deprecated~~ | ~~9B~~       | ~~16K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Pro/01-ai/Yi-1.5-9B-Chat-16K~~                  | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~0.7~~    | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen1.5-14B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型经过大规模数据预训练，并通过监督微调和直接偏好优化进行后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该模型支持 32K 的上下文长度，无需使用 trust_remote_code~~ | ~~Deprecated~~ | ~~14B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Qwen/Qwen1.5-14B-Chat~~                         | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen1.5-110B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置、组查询注意力等技术，并改进了适用于多种自然语言和代码的分词器。该 110B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能~~ | ~~Deprecated~~ | ~~110B~~     | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Qwen/Qwen1.5-110B-Chat~~                        | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~&nbsp;~~ | ~~&nbsp;~~ | ~~&nbsp;~~          | ~~&nbsp;~~ | ~~Qwen1.5-7B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该 7B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能~~ | ~~Deprecated~~ | ~~Free~~     | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~免费~~                                          | ~~Qwen/Qwen1.5-7B-Chat~~                      | ~~对话~~   |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~1.26~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen1.5-32B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置、组查询注意力等技术，并改进了适用于多种自然语言和代码的分词器。该 32B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能~~ | ~~Deprecated~~ | ~~32B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Qwen/Qwen1.5-32B-Chat~~                         | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen1.5-7B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该 7B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能~~ | ~~Deprecated~~ | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Pro/Qwen/Qwen1.5-7B-Chat~~                      | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力~~ | ~~Deprecated~~ | ~~72B~~      | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Qwen/Qwen2-72B-Instruct~~                       | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2.5-Math-72B 是阿里云发布的 Qwen2.5-Math 系列数学大语言模型之一。该模型支持使用思维链（CoT）和工具集成推理（TIR）方法解决中文和英文数学问题。相比前代 Qwen2-Math 系列，Qwen2.5-Math 系列在中英文数学基准测试中取得了显著的性能提升。该模型在处理精确计算、符号操作和算法操作方面表现出色，尤其适合解决复杂的数学和算法推理任务~~ | ~~Deprecated~~ | ~~Math~~     | ~~72B~~      | ~~4K~~       | ~~&nbsp;~~   | ~~Qwen/Qwen2.5-Math-72B-Instruct~~                | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![书生·浦语](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/internlm.svg+xml)~~ | ~~&nbsp;~~                                      | ~~书生·浦语~~   | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域~~ | ~~Deprecated~~ | ~~Tools~~    | ~~7B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~Pro/internlm/internlm2_5-7b-chat~~              | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![智谱 AI](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Zhipu.svg+xml)~~ | ~~&nbsp;~~                                      | ~~智谱 AI~~     | ~~￥~~     | ~~0.35~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用~~ | ~~Deprecated~~ | ~~6B~~       | ~~32K~~      | ~~&nbsp;~~   | ~~&nbsp;~~   | ~~Pro/THUDM/chatglm3-6b~~                         | ~~对话~~                                      | ~~&nbsp;~~ |
| ~~&nbsp;~~                          | ~~![Qwen](./%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%E5%8F%8A%E4%BF%A1%E6%81%AF.assets/Tongyi.svg+xml)~~ | ~~&nbsp;~~                                      | ~~Qwen~~        | ~~￥~~     | ~~4.13~~   | ~~/ M Tokens~~      | ~~💰🎁~~     | ~~Qwen2-Math-72B-Instruct 是 Qwen2 数学系列中的指令微调大语言模型，参数规模为 72B。该模型专门针对数学和算术问题解决能力进行了优化，在数学推理方面表现出色，超越了开源模型甚至一些闭源模型（如 GPT4）的数学能力。它基于 Qwen2 系列构建，旨在解决需要复杂、多步逻辑推理的高级数学问题。该模型目前主要支持英语，双语（英语和中文）版本将很快发布~~ | ~~Deprecated~~ | ~~Math~~     | ~~72B~~      | ~~4K~~       | ~~&nbsp;~~   | ~~Qwen/Qwen2-Math-72B-Instruct~~                  | ~~对话~~                                      | ~~&nbsp;~~ |

> 2025-7-16 18:53:36

用的比较少，放个模型列表在这

model_name,publisher,family,domain_type,labels,params,context_size,heat,input_price,output_price,api_url,description,model_date
Wan2.1-i2v-14B,阿里云,通义万相,VISION,视频生成,14B,8192,137,,,https://zhenze-huhehaote.cmecloud.cn/v1/video/generate,Wan2.1-i2v-14B是一款先进的图像到视频生成模型，基于140亿参数构建，专为高质量视觉内容转换设计。它利用强大的深度学习技术，能够将静态图像转化为生动的视频片段，支持多种风格和场景扩展。该模型强调细节保真与流畅性，适用于创意媒体制作、动态展示等多个领域。,2025-06-18 23:08:35
DeepSeek-R1-0528,deepseek-ai,deepseek,TEXT,文本对话,671B,32768,637,4,16,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1377903472851279872/v1/chat/completions,DeepSeek-R1-0528是DeepSeek发布的新版本，其通过强化后训练显著提升了思维深度与推理能力，在数学、编程和通用逻辑等领域表现卓越，同时在复杂指令处理、长文本处理稳定性、代码生成质量等方面也有显著优化，幻觉率降低，创意写作能力增强，可助力用户安全、稳定地构建智能应用。,2025-05-29 23:51:10
Paraformer-large-zh-cn-16k,阿里,通义千问,SPEECH,语音识别,,4096,247,,,http://zhenze-huhehaote.cmecloud.cn/v1/audio/transcriptions,Paraformer是达摩院语音团队提出的一种高效的非自回归端到端语音识别框架，集成VAD、ASR、标点与时间戳功能，可直接对时长为数小时音频进行识别，并输出带标点文字与时间戳，模型可以被应用于语音输入法、语音导航、智能会议纪要等场景。,2025-05-16 14:21:34
DeepSeek-V3-0324,deepseek-ai,deepseek,TEXT,文本对话,671B,65536,1569,2,8,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1381731785138085888/v1/chat/completions,DeepSeek-V3是一款由中国AI领域前沿公司精心研发的MoE模型，其参数规模高达671B，专为处理复杂、大规模的数据任务而设计。该模型引入了先进的多头潜在注意力（MLA）机制和DeepSeekMoE架构，这些创新技术不仅显著提升了模型的计算效率和性能，还使其在处理自然语言理解、生成以及其他AI任务时表现出色。DeepSeek-V3在保持高效推理的同时，也展现了强大的泛化能力和适应性，能够应对各种复杂场景和挑战。其卓越的性能和广泛的应用前景，使其在AI领域具有极高的竞争力和影响力。无论是学术研究还是商业应用，DeepSeek-V3都将成为推动AI技术发展的重要力量，为用户带来更加智能、高效和便捷的AI服务体验。,2025-03-31 00:00:00
QVQ-72B-Preview,阿里云,通义千问,VISION,图片理解,72B,32768,57,,,N/A,QVQ-72B-Preview 是由 Qwen 团队开发的专注于增强视觉推理能力模型，它在多模态大规模多任务理解（MMMU）基准测试中获得了70.3%的优异成绩，展示了 QVQ 在跨学科理解和推理方面的强大能力。此外，在 MathVision 上的显著改进也突显了该模型在数学推理任务上的进步。,2025-03-01 00:00:00
DeepSeek-R1,deepseek-ai,deepseek,TEXT,文本对话,671B,10240,14697,4,16,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336781912337387520/v1/chat/completions,DeepSeek-R1是一款由中国AI创新企业倾力打造的革命性MoE模型，其设计核心聚焦于提供高度精确且高效的AI解决方案。该模型拥有精心调优的架构，专为处理多样化、高要求的数据挑战而生。DeepSeek-R1融合了前沿的深度学习与混合专家系统理念，通过引入创新的算法优化和增强的模型组件，极大地提升了处理速度和预测准确性。它不仅在自然语言处理、图像识别等核心AI任务中展现出卓越性能，还凭借其出色的泛化能力和灵活性，能够轻松应对多种复杂应用场景。DeepSeek-R1的高效性、稳定性和广泛的应用潜力，使其在AI技术的前沿探索中占据了一席之地，无论是科研探索还是行业实践，都将为用户带来前所未有的智能体验和价值提升。,2025-02-17 08:00:00
DeepSeek-V2,deepseek-ai,deepseek,TEXT,文本对话,236B,10240,1290,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336842224447197184/v1/chat/completions,DeepSeek-V2 是一款由国内 AI 先锋企业全力打造的创新模型，它拥有高达236B的参数规模，专注于应对复杂多样的数据处理难题。该模型创新性地融合了高效的注意力优化算法以及独特的架构设计，这些先进技术极大地提高了模型的运算速度与准确性。,2025-02-05 23:23:33
DeepSeek-V3,deepseek-ai,deepseek,TEXT,文本对话,671B,32768,2655,2,8,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336844822260682752/v1/chat/completions,DeepSeek-V3是一款由中国AI领域前沿公司精心研发的MoE模型，其参数规模高达671B，专为处理复杂、大规模的数据任务而设计。该模型引入了先进的多头潜在注意力（MLA）机制和DeepSeekMoE架构，这些创新技术不仅显著提升了模型的计算效率和性能，还使其在处理自然语言理解、生成以及其他AI任务时表现出色。DeepSeek-V3在保持高效推理的同时，也展现了强大的泛化能力和适应性，能够应对各种复杂场景和挑战。其卓越的性能和广泛的应用前景，使其在AI领域具有极高的竞争力和影响力。无论是学术研究还是商业应用，DeepSeek-V3都将成为推动AI技术发展的重要力量，为用户带来更加智能、高效和便捷的AI服务体验。,2025-02-05 22:12:32
DeepSeek-R1-Distill-Llama-70B,deepseek-ai,deepseek,TEXT,文本对话,70B,32768,905,4.13,4.13,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1337014908971847680/v1/chat/completions,DeepSeek-R1-Distill-Llama-70B通过知识蒸馏技术，从大型模型中提取关键知识，并将其压缩到较小的模型中。这种技术使得小模型能够继承大型模型的优点，同时减少计算资源和内存的使用。尽管是蒸馏模型，但DeepSeek-R1-Distill-Llama-70B在保持较高精度的同时，显著提高了推理速度。这使得它能够在多种应用场景中快速响应，提高用户体验。该模型具有70B的参数规模，这在性能与计算资源消耗之间达到了较好的平衡。相较于原始的Llama-70B模型，它更加轻便且易于部署。DeepSeek-R1-Distill-Llama-70B支持多种自然语言处理任务，包括文本生成、语言理解、问答系统等。这使得它能够满足广泛的应用需求。,2025-02-05 22:00:00
DeepSeek-R1-Distill-Qwen-32B,deepseek-ai,deepseek,TEXT,文本对话,32B,32768,1035,1.26,1.26,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336818550402912256/v1/chat/completions,DeepSeek-R1-Distill-Qwen-32B是DeepSeek-R1系列模型的一个迭代版本，经过蒸馏处理，旨在提供更高效、更轻量级的推理能力。该模型源自DeepSeek项目，该项目致力于通过大规模强化学习（RL）训练出具有卓越推理性能的AI模型。DeepSeek-R1-Distill-Qwen-32B基于Qwen-2.5系列进行微调，继承了其强大的推理基因。DeepSeek-R1-Distill-Qwen-32B模型在多个领域具有广泛的应用前景，包括但不限于自然语言处理、数学计算、代码生成等。其高效的推理能力和开源的特性使得它成为AI研究和应用中的热门选择。,2025-02-05 21:56:00
DeepSeek-R1-Distill-Qwen-1.5B,deepseek-ai,deepseek,TEXT,文本对话,1.5B,32768,562,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336818119238848512/v1/chat/completions,DeepSeek-R1-Distill-Qwen-1.5B是DeepSeek-R1系列模型的一个迭代版本，经过蒸馏处理，旨在提供更高效、更轻量级的推理能力。该模型源自DeepSeek项目，该项目致力于通过大规模强化学习（RL）训练出具有卓越推理性能的AI模型。DeepSeek-R1-Distill-Qwen-1.5B基于Qwen-2.5系列进行微调，继承了其强大的推理基因。DeepSeek-R1-Distill-Qwen-1.5B模型在多个领域具有广泛的应用前景，包括但不限于自然语言处理、数学计算、代码生成等。其高效的推理能力和开源的特性使得它成为AI研究和应用中的热门选择。,2025-02-05 21:51:27
DeepSeek-R1-Distill-Llama-8B,deepseek-ai,deepseek,TEXT,文本对话,8B,32768,244,0.42,0.42,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336813642429698048/v1/chat/completions,DeepSeek-R1-Distill-Llama-8B融合了DeepSeek-R1的先进知识蒸馏技术，使得小模型能够学习到大型模型的优秀特征。这种技术不仅减小了模型的参数规模，还保留了强大的语言理解和生成能力。该模型具有8B的参数规模，这在性能与计算资源消耗之间达到了较好的平衡。相较于原始的DeepSeek-R1模型，它更加轻便且易于部署。由于经过蒸馏处理，DeepSeek-R1-Distill-Llama-8B在推理速度方面表现出色，能够在多种设备（包括消费级设备）上实现快速响应。该模型支持多种任务，包括分类、奖励预测、嵌入、生成和评分等，适用于广泛的应用场景。,2025-02-05 21:34:24
DeepSeek-Coder-33B-Instruct,deepseek-ai,deepseek,TEXT,文本对话,33B,16384,211,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1337648992120750080/v1/chat/completions,DeepSeek Coder系列中的旗舰模型——deepseek-coder-33b-instruct，以其庞大的330亿参数规模，在代码生成与理解领域树立了新的标杆。这款模型基于海量的多语言代码与自然语言数据训练而成，不仅精通多种编程语言，还能深刻理解自然语言指令，实现精准的代码生成与补全。deepseek-coder-33b-instruct通过精细的指令微调，进一步提升了模型对复杂编程任务的应对能力，无论是代码翻译、优化还是项目级别的代码生成，都能游刃有余。其卓越的性能在多个基准测试中得到了验证，展现了DeepSeek在代码语言模型领域的深厚积累与创新实力。,2025-02-05 21:17:00
DeepSeek-Coder-6.7B-Instruct,deepseek-ai,deepseek,TEXT,文本对话,6.7B,16384,85,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1337650062129643520/v1/chat/completions,DeepSeek Coder系列中的deepseek-coder-6.7b-instruct模型拥有67亿参数，基于庞大的训练数据集，其中包括丰富的代码样本和自然语言描述，使其能够深入理解编程逻辑并精准响应自然语言指令.deepseek-coder-6.7b-instruct在代码生成、补全、翻译及优化等多个方面展现出卓越的性能。其强大的生成能力得益于先进的指令微调技术，使得模型能够生成高质量、符合用户需求的代码。此外，该模型还支持多种编程语言，并具备出色的跨语言理解能力。deepseek-coder-6.7b-instruct不仅适用于个人开发者提升编程效率，也是企业实现自动化代码生成和优化的理想选择。,2025-02-05 21:15:00
DeepSeek-V2-Lite-Chat,deepseek-ai,deepseek,TEXT,文本对话,16B,32768,102,1.33,1.33,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1337016647923896320/v1/chat/completions,DeepSeek-V2-Lite-Chat是一款轻量级、高效的智能聊天机器人，专为满足用户即时通讯需求而设计。它采用先进的深度学习和自然语言处理技术，能够理解用户意图，提供连贯、自然的对话体验。该系统支持多轮对话，能够自动适应不同话题和语境，同时根据用户兴趣和历史对话提供个性化推荐。DeepSeek-V2-Lite-Chat还具备情感分析能力，能够识别用户情绪并提供相应的情感支持。此外，它支持多种语言，方便国际用户使用。在保障用户隐私方面，DeepSeek-V2-Lite-Chat严格遵守隐私政策，确保用户数据安全。该系统适用于个人聊天、客户服务、教育辅导和心理健康等多个场景，未来将持续优化算法模型，拓展应用场景，为用户提供更加智能、便捷和安全的对话服务。,2025-02-05 21:15:00
DeepSeek-Coder-1.3B-Instruct,deepseek-ai,deepseek,TEXT,文本对话,1.3B,16384,87,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1337018840192323584/v1/chat/completions,DeepSeek Coder系列中的deepseek-coder-1.3b-instruct模型是一款功能强大的代码语言模型，它基于2T tokens的训练数据，其中87%为代码，13%为自然语言数据，使其兼具理解代码逻辑和处理自然语言指令的能力。该模型拥有1.3B参数，支持最大16K的窗口大小，能够处理复杂的代码任务。通过采用额外的填空任务，deepseek-coder-1.3b-instruct实现了项目级别的代码补全和填充，显著提高了代码生成的效率和准确性。在多个编程语言和基准测试中，该模型表现出色，达到了开源代码模型中的领先水平。deepseek-coder-1.3b-instruct适用于各种代码相关的任务和应用场景，如代码生成、补全、审查和优化等。作为DeepSeek提供的一款高级代码语言模型，它遵循MIT许可证并支持商业使用，是开发者提高编程效率和质量的得力助手。,2025-02-05 21:13:00
DeepSeek-R1-Distill-Qwen-7B,deepseek-ai,deepseek,TEXT,文本对话,7B,32768,185,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336810595559247872/v1/chat/completions,DeepSeek-R1-Distill-Qwen-7B是DeepSeek-R1系列模型的一个迭代版本，经过蒸馏处理，旨在提供更高效、更轻量级的推理能力。该模型源自DeepSeek项目，该项目致力于通过大规模强化学习（RL）训练出具有卓越推理性能的AI模型。DeepSeek-R1-Distill-Qwen-7B基于Qwen-2.5系列进行微调，继承了其强大的推理基因。DeepSeek-R1-Distill-Qwen-7B模型在多个领域具有广泛的应用前景，包括但不限于自然语言处理、数学计算、代码生成等。其高效的推理能力和开源的特性使得它成为AI研究和应用中的热门选择。,2025-02-05 21:10:52
DeepSeek-R1-Distill-Qwen-14B,deepseek-ai,deepseek,TEXT,文本对话,14B,32768,141,0.7,0.7,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1336703912621314048/v1/chat/completions,DeepSeek-R1-Distill-Qwen-14B是DeepSeek-R1系列模型的一个迭代版本，经过蒸馏处理，旨在提供更高效、更轻量级的推理能力。该模型源自DeepSeek项目，该项目致力于通过大规模强化学习（RL）训练出具有卓越推理性能的AI模型。DeepSeek-R1-Distill-Qwen-14B基于Qwen-2.5系列进行微调，继承了其强大的推理基因。DeepSeek-R1-Distill-Qwen-14B模型在多个领域具有广泛的应用前景，包括但不限于自然语言处理、数学计算、代码生成等。其高效的推理能力和开源的特性使得它成为AI研究和应用中的热门选择。,2025-02-05 14:03:05
DeepSeek-R1-FP16,deepseek-ai,deepseek,TEXT,文本对话,671B,65536,132,,,N/A,DeepSeek-R1是一款由中国AI创新企业倾力打造的革命性MoE模型，其设计核心聚焦于提供高度精确且高效的AI解决方案。该模型拥有精心调优的架构，专为处理多样化、高要求的数据挑战而生。DeepSeek-R1融合了前沿的深度学习与混合专家系统理念，通过引入创新的算法优化和增强的模型组件，极大地提升了处理速度和预测准确性。它不仅在自然语言处理、图像识别等核心AI任务中展现出卓越性能，还凭借其出色的泛化能力和灵活性，能够轻松应对多种复杂应用场景。DeepSeek-R1的高效性、稳定性和广泛的应用潜力，使其在AI技术的前沿探索中占据了一席之地，无论是科研探索还是行业实践，都将为用户带来前所未有的智能体验和价值提升。,2025-02-05 09:00:00
DeepSeek-V3-Long,deepseek-ai,deepseek,TEXT,文本对话,671B,65536,427,,,N/A,DeepSeek-V3是一款由中国AI领域前沿公司精心研发的MoE模型，其参数规模高达671B，专为处理复杂、大规模的数据任务而设计。该模型引入了先进的多头潜在注意力（MLA）机制和DeepSeekMoE架构，这些创新技术不仅显著提升了模型的计算效率和性能，还使其在处理自然语言理解、生成以及其他AI任务时表现出色。DeepSeek-V3在保持高效推理的同时，也展现了强大的泛化能力和适应性，能够应对各种复杂场景和挑战。其卓越的性能和广泛的应用前景，使其在AI领域具有极高的竞争力和影响力。无论是学术研究还是商业应用，DeepSeek-V3都将成为推动AI技术发展的重要力量，为用户带来更加智能、高效和便捷的AI服务体验。,2025-02-05 00:00:00
JIUTIAN-13.9B-8K-Chat,jiutian-AI,九天,TEXT,文本对话,13.9B,8192,27,,,N/A,JIUTIAN-13.9B-8K-Chat是中国移动自主研发的语言大模型，实现数据构建、预训练、微调、部署全链路核心技术自主创新；行业定向增强，数据上融合通信、能源等8大行业专业知识，提供定制化行业大模型；安全可靠，建立数据质量评估体系，加强数据处理和清洗，优化DPO算法，加强人类价值观对齐，实现指令安全响应。在主流中文评测数据集上，性能已经与GPT-4对齐，适配国产算力生态，助力企业实现智能化产业升级。,2025-02-01 00:00:00
Qwen-VL-Chat,阿里云,通义千问,VISION,图片理解,9B,2048,34,,,N/A,Qwen-VL-Chat是阿里云研发的大规模视觉语言模型Qwen-VL系列中的Chat模型，基于Qwen-VL打造。它可应用于视觉问答、文字理解、图表数学推理、多图理解等多方面。,2025-02-01 00:00:00
JIUTIAN-75B-8K-Chat,JiuTian-AI,九天,TEXT,文本对话,75B,8192,180,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1359268848745529344/v1/chat/completions,JIUTIAN-75B-8K-Chat是中国移动自主研发的语言大模型，实现数据构建、预训练、微调、部署全链路核心技术自主创新；行业定向增强，数据上融合通信、能源等8大行业专业知识，提供定制化行业大模型；安全可靠，建立数据质量评估体系，加强数据处理和清洗，优化DPO算法，加强人类价值观对齐，实现指令安全响应。在主流中文评测数据集上，性能已经与GPT-4对齐，适配国产算力生态，助力企业实现智能化产业升级。,2025-02-01 00:00:00
Zhanlu-7B,移动云,湛卢,TEXT,文本对话,7B,32768,10,,,N/A,zhanlu-7B是移动云推出的研发大模型之一，有70亿参数。融合海量代码库、技术文档及研发知识，构建强大的智能编程能力，具备长上下文理解能力，在代码生成方面支持深度思考模式，可结合用户需求进行自主开发和代码自动修复，在HumanEval等权威代码评测中达到行业领先水平。,2025-02-01 00:00:00
InternVL2-40B,上海人工智能实验室,书生浦语,VISION,"图片理解, 视频理解",40B,8192,22,,,N/A,InternVL2-40B是上海人工智能实验室OpenGVLab发布的多模态大语言模型，参数规模达400亿。该模型采用ViT-MLP-LLM架构，支持图像、文字等多模态输入，具备强大的真实世界感知能力。在多学科问答（MMMU）任务上，它在文档理解、OCR、科学问题解决等任务中表现卓越，性能超越大多数开源模型，与专有商业模型相当。,2025-02-01 00:00:00
InternVL2-8B,上海人工智能实验室,书生浦语,VISION,"图片理解, 视频理解",8B,32768,16,,,N/A,InternVL2-8B 是由上海人工智能实验室推出的先进多模态大语言模型，参数规模达 8.1B。它具备强大的多模态处理能力，可接受图像、视频等多种模态输入。在文档理解、OCR、科学问题解决等复杂任务上展现卓越性能，凭借高精度与强泛化能力，为多领域应用提供有力支持。,2025-02-01 00:00:00
jina-embeddings-v2-base-en,jina,jina,VECTOR,文本对话,137M,8192,27,,,N/A,jina-embeddings-v2-base-en 是一个支持 8192 序列长度 的单语种（英语）嵌入模型。该模型基于 BERT 架构（JinaBERT），支持对称双向变体的 ALiBi，以允许更长的序列长度。,2025-02-01 00:00:00
JIUTIAN-13.9B-8K-Chat,jiutian-AI,九天,TEXT,文本对话,13.9B,8192,27,,,N/A,JIUTIAN-13.9B-8K-Chat是中国移动自主研发的语言大模型，实现数据构建、预训练、微调、部署全链路核心技术自主创新；行业定向增强，数据上融合通信、能源等8大行业专业知识，提供定制化行业大模型；安全可靠，建立数据质量评估体系，加强数据处理和清洗，优化DPO算法，加强人类价值观对齐，实现指令安全响应。在主流中文评测数据集上，性能已经与GPT-4对齐，适配国产算力生态，助力企业实现智能化产业升级。,2025-02-01 00:00:00
JIUTIAN-75B-8K-Chat,JiuTian-AI,九天,TEXT,文本对话,75B,8192,180,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1359268848745529344/v1/chat/completions,JIUTIAN-75B-8K-Chat是中国移动自主研发的语言大模型，实现数据构建、预训练、微调、部署全链路核心技术自主创新；行业定向增强，数据上融合通信、能源等8大行业专业知识，提供定制化行业大模型；安全可靠，建立数据质量评估体系，加强数据处理和清洗，优化DPO算法，加强人类价值观对齐，实现指令安全响应。在主流中文评测数据集上，性能已经与GPT-4对齐，适配国产算力生态，助力企业实现智能化产业升级。,2025-02-01 00:00:00
Qwen-VL-Chat,阿里云,通义千问,VISION,图片理解,9B,2048,34,,,N/A,Qwen-VL-Chat是阿里云研发的大规模视觉语言模型Qwen-VL系列中的Chat模型，基于Qwen-VL打造。它可应用于视觉问答、文字理解、图表数学推理、多图理解等多方面。,2025-02-01 00:00:00
Wan2.1-T2V-14B,阿里云,通义万相,VISION,视频生成,14B,,19,,,N/A,"Wan2.1-T2V-14B是一款基于先进多模态大模型开发的文生视频（Text-to-Video, T2V）生成模型，参数量达140亿，专注于将自然语言描述转化为高质量、连贯的动态视频内容。当前版本支持文生图（Text-to-Image）功能，可生成细节丰富、风格多样的静态图像，为后续视频生成提供基础能力。",2025-01-31 00:00:00
bge-reranker-v2-m3,BAAI,bge,RERANK,文本对话,568M,8192,42,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1377771645169614848/v1/rerank,bge-reranker-v2-m3是由北京智源人工智能研究院推出的一款轻量级重排模型。它拥有强大的多语言处理能力，能够处理多种不同语言的文本，在跨语言场景中表现出色。此外，它的推理速度快，可高效处理大量文本数据，在保证处理结果准确性的同时，极大地提升了处理效率，适用于对响应时间要求较高的场景。,2025-01-31 00:00:00
bge-large-zh-v1.5,BAAI,bge,VECTOR,文本对话,335M,512,148,,,N/A,BGE-large-zh-v1.5是由BAAI（Beijing Academy of Artificial Intelligence）开发的中文嵌入模型，基于Transformer架构，专门设计用于句子级别的特征提取和相似度计算。该模型在中文语境下的任务中表现出色，如句子相似度、文本检索和问答系统，具有准确率高、推理速度快、资源消耗低等优势。,2025-01-31 00:00:00
Qwen2.5-72B-Instruct-64K,阿里云,通义千问,TEXT,文本对话,72B,65536,17,,,,Qwen2.5-72B-Instruct-64K 是一款具备 720 亿参数的强大语言模型，拥有 64K 上下文窗口，可深度理解海量信息，精准遵循复杂指令，在多语言交互与长文本任务处理上表现极为出色。,2025-01-31 00:00:00
CosyVoice,阿里云,通义千问,SPEECH,语音合成,0.5B,,18,,,N/A,Co‌syVoice是一款创新的语音合成系统，采用先进的语音量化编码技术和大规模生成模型架构。该系统通过深度神经网络实现了文本语义理解与语音生成的有机融合，能够智能解析各类文本内容，并利用离散编码技术将其转换为高度自然的人声语音输出。其核心技术优势在于结合了大语言模型的强大理解能力和语音量化编码的精确控制，最终呈现出媲美真人发声的流畅语音体验。,2025-01-31 00:00:00
bge-reranker-large,BAAI,bge,RERANK,文本对话,560M,512,115,,,N/A,bge-reranker-large是由北京智源人工智能研究院推出的高效重排序模型，采用交叉编码器架构，专为检索增强生成任务设计，能有效提升中文及英文检索结果的准确性和相关性排序，通过深入分析查询与候选文本的语义联系，确保最相关文档优先展示，实现检索性能的优化。,2025-01-31 00:00:00
glm-4-9b,智谱 AI,智谱清言,TEXT,文本对话,9B,8192,59,,,N/A,GLM-4-9B 是智谱 AI 推出的最新一代预训练模型 GLM-4 系列中的开源版本。 在语义、数学、推理、代码和知识等多方面的数据集测评中，GLM-4-9B 及其人类偏好对齐的版本 GLM-4-9B-Chat 均表现出较高的性能。,2025-01-10 19:09:45
internlm-7b,上海人工智能实验室,internlm,TEXT,文本对话,7B,16384,20,,,N/A,InternLM 是一个针对实际场景定制的 700 亿参数基础模型。该模型具有以下特点：它利用数万亿高质量标记进行训练，以建立一个强大的知识库。它为用户提供了一个灵活构建自定义工作流程的多功能工具集。,2025-01-10 19:04:56
Qwen2.5-72B-Instruct-128K,阿里云,通义千问,TEXT,文本对话,72B,131072,7,,,N/A,Qwen2.5-72B-Instruct-128K 是一款具备 720 亿参数的强大语言模型，拥有 128K 超长上下文窗口，可深度理解海量信息，精准遵循复杂指令，在多语言交互与长文本任务处理上表现极为出色。,2025-01-01 00:00:00
Qwen2.5-VL-32B-Instruct,阿里云,通义千问,VISION,"图片理解, 视频理解",32B,32768,81,,,http://zhenze-huhehaote.cmecloud.cn/v1/chat/completions,Qwen2.5-VL-32B 是阿里推出的 320 亿参数规模的多模态模型，在 Qwen2.5-VL 系列既有优势基础上，借助强化学习，进一步优化了模型。在数学及问题解决方面，其能力得到大幅提升，可处理几何、代数等复杂数学问题，并进行多步骤逻辑推导 。同时，该模型对回复风格做出调整，使其更贴合人类偏好，显著改善了用户的主观体验。尤其在解答数学、逻辑推理、知识问答等客观性问题时，模型回复的细节丰富度和格式清晰度得到明显增强，能够给出更清晰、条理分明的回答。,2024-12-31 00:00:00
Qwen2.5-VL-72B-Instruct,阿里云,通义千问,VISION,"视频理解, 图片理解",72B,32768,90,,,http://zhenze-huhehaote.cmecloud.cn/v1/chat/completions,Qwen2.5-VL-72B-Instruct 是阿里通义千问推出的 Qwen2.5-VL 模型家族旗舰版，有 720 亿参数。在与顶尖及同规模优秀模型的评估对比中，它在多领域任务基准测试中表现出色，能解答大学难题、处理复杂数学问题，在文档和图表理解上优势明显，还可准确应对通用问答，理解超 1 小时长视频并捕捉事件。此外，它无需针对特定任务微调就能充当视觉代理，集成到设备中执行复杂任务，在 13 项权威评测中超越 GPT-4o 与 Claude3.5，是视觉理解领域的领先模型。,2024-12-31 00:00:00
Qwen2.5-7B-Instruct-Int8,阿里云,通义千问,TEXT,文本对话,7B,32768,24,,,N/A,Qwen2.5-7B-Instruct-Int8是Qwen系列中的一款大型语言模型，基于Transformer架构，拥有约70亿个非嵌入参数，并在超过18T的大规模数据集上进行了预训练。Qwen2.5-7B-Instruct-Int8还采用了Int8量化技术，这种技术可以在不显著降低模型性能的前提下，大幅度减少模型的存储需求和计算量，使得模型更加高效、节能，并更适合在资源受限的环境中部署。,2024-12-31 00:00:00
Qwen2.5-Math-72B-Instruct,阿里云,通义千问,TEXT,文本对话,72B,4096,37,,,N/A,Qwen2.5-Math-72B-Instruct是一款拥有720亿参数的大型语言模型，专为数学理解和生成而设计，基于Qwen2.5框架，通过指令调优技术提升了模型对数学问题的理解和解答能力，适用于数学教育、科学计算、金融分析等多个领域，为用户提供精准、高效的数学辅助服务。,2024-12-31 00:00:00
Qwen2.5-Coder-32B-Instruct,阿里云,通义千问,TEXT,文本对话,32B,32768,42,,,N/A,Qwen2.5-Coder-32B-Instruct是一款基于Qwen2.5框架，拥有320亿参数的先进编程辅助模型，通过指令调优技术深度优化，擅长理解复杂编程需求、自动生成高质量代码，并支持多种编程语言，是开发者提升编程效率、解决编程难题的得力助手。,2024-12-31 00:00:00
Qwen2.5-Coder-32B,阿里云,通义千问,TEXT,文本对话,32B,32768,63,,,N/A,Qwen2.5-Coder-32B是阿里云通义大模型团队推出的开源代码生成模型的旗舰版本，该模型基于强大的Qwen2.5架构构建，在代码生成、代码推理和代码修复等任务上表现出色，刷新了多个主流基准测试的得分记录。它支持128k token的上下文长度，能高效捕捉代码中的长距离依赖关系，适用于多种编程语言和开发环境。,2024-12-31 00:00:00
Qwen2-VL-72B-Instruct,阿里云,通义千问,VISION,"图片理解, 视频理解",72B,32768,174,,,http://zhenze-huhehaote.cmecloud.cn/v1/chat/completions,Qwen2-VL-72B 由阿里推出，拥有 720 亿参数。从多个维度对其视觉能力进行了评估，结果表明Qwen2-VL-72B在文档理解上优势显著，支持多语言文字图像识别；在数学解题、长视频理解及设备联动方面同样表现出色。,2024-12-31 00:00:00
Qwen2-VL-7B-Instruct,阿里云,通义千问,VISION,"图片理解, 视频理解",7B,32768,36,,,http://zhenze-huhehaote.cmecloud.cn/v1/chat/completions,Qwen2-VL-7B-Instruct 由阿里推出，拥有 70 亿参数的多模态理解类模型。在视觉理解上，该模型在 MathVista、DocVQA 等视觉理解基准测试中，对不同分辨率与比例的图像，均能精准解析，成绩领先。视频处理方面，它可理解时长超 20 分钟的视频，为视频问答、内容创作等提供助力。凭借强大的推理和决策能力，Qwen2-VL-7B-Instruct 能与手机、机器人等设备集成，依据视觉环境和文本指令自动操作 。,2024-12-31 00:00:00
Qwen2.5-VL-7B-Instruct,阿里云,通义千问,VISION,"图片理解, 视频理解",7B,32768,40,,,http://zhenze-huhehaote.cmecloud.cn/v1/chat/completions,Qwen2.5-VL-7B-Instruct 是由阿里通义千问推出的Qwen2.5-VL 模型家族 70 亿参数规模的多模态理解模型，在视觉与语言交互方面优势显著。它既能识别常见物体，又能深入分析图像中的各类元素，还可充当视觉代理操作设备执行复杂任务，能理解超 1 小时长视频并捕捉事件，精准定位图像物体并输出稳定坐标属性。,2024-12-31 00:00:00
Bloom-7B1,bigscience,bloom,TEXT,文本对话,7B,4096,0,,,N/A,Bloom-7B1是一个开源的多语言预训练模型，旨在减少偏见和提升可解释性，以符合伦理标准，拥有70亿参数。,2024-12-31 00:00:00
Qwen-72B-Chat,阿里云,通义千问,TEXT,文本对话,72B,32768,44,,,N/A,Qwen-72B-Chat是阿里云推出的通义千问大模型系列中的一款旗舰产品，拥有720亿参数，基于广泛的预训练数据和优化的Transformer架构，通过先进的对齐机制打造，具备卓越的对话、创作、摘要、信息抽取、翻译及代码生成能力，为用户带来高效、智能的交互体验。,2024-12-31 00:00:00
MS-LongWriter-Qwen2.5-7B-Instruct,阿里云,通义千问,TEXT,文本对话,7B,32768,123,,,N/A,MS-LongWriter-Qwen2.5-7B-Instruct是一款基于阿里云通义千问大模型系列，专为长文本创作与编辑领域设计的高级指令理解模型，拥有70亿参数规模。该模型在广泛的文学作品、学术论文、新闻报道、专业文章以及高质量写作指南等数据源上进行了深度训练与优化，以确保对长文本创作的深刻理解与高效支持。MS-LongWriter-Qwen2.5-7B-Instruct擅长处理一系列与长文本创作及编辑相关的复杂任务，包括但不限于文章构思与大纲制定、内容创作与润色、结构优化与逻辑梳理、语言风格调整与校对、参考文献引用与管理以及个性化写作建议等。,2024-12-30 15:29:28
Qwen2.5-Coder-7B-Instruct,阿里云,通义千问,TEXT,文本对话,7B,32768,44,,,N/A,Qwen2.5-Coder-7B-Instruct是阿里云通义千问大模型系列中，专为编程与软件开发领域设计的高级指令理解模型，具备70亿参数规模。该模型在广泛的编程教程、代码库、开发者文档、技术论坛以及权威编程指南等高质量数据源上进行了深度训练与优化，以确保对编程语言特性、软件开发流程、算法设计以及代码调试等知识的深入掌握。Qwen2.5-Coder-7B-Instruct擅长处理一系列与编程及软件开发相关的复杂任务，包括但不限于代码编写与修改建议、编程问题解答、算法实现与优化、代码审查与调试、软件项目规划与管理、技术文档撰写以及编程语言学习辅导等,2024-12-30 15:12:28
BioMistral-7B,Mistral AI,Mistral,TEXT,文本对话,7B,32768,50,,,N/A,BioMistral-7B是一款专为生物医学领域设计的先进大型语言模型，拥有70亿参数规模，旨在提供精准、高效且全面的生物医学信息处理与理解能力。该模型在广泛搜集的生物医学文献、临床试验数据、专业数据库以及权威医学词典等高质量数据源上进行了深度训练与优化，以确保对生物医学领域知识的深入掌握。该模型擅长处理一系列生物医学相关的复杂任务，包括但不限于医学文献摘要生成、疾病诊断辅助、药物研发信息检索、基因序列分析、临床案例研究、生物医学问答以及医疗健康咨询等。,2024-12-30 14:17:32
Qwen2.5-0.5B-Instruct,阿里云,通义千问,TEXT,文本对话,0.5B,32768,46,,,N/A,Qwen2.5-0.5B-instruct是阿里云通义千问大模型系列中的一款精心调优的基础指令理解模型，拥有5亿参数规模，专为提升对指令的精确理解和执行能力而设计。虽然其参数量相较于更大版本的模型有所精简，但Qwen2.5-0.5B-instruct通过先进的指令调优技术，在广泛的多样化预训练数据集上进行了深度优化，确保了模型在保持高效性的同时，能够准确捕捉并响应各种复杂指令。,2024-12-30 14:11:01
Qwen2.5-0.5B,阿里云,通义千问,TEXT,文本对话,0.5B,32768,12,,,N/A,Qwen2.5-0.5B模型是阿里云通义千问大模型系列中的基础而精炼的版本，拥有5亿参数规模，专为高效与实用性而设计。该模型在广泛的预训练数据资源上进行了精心训练，确保了扎实且多样的语言理解能力。尽管其规模相较于更大版本更为紧凑，Qwen2.5-0.5B依然能够胜任多种基本的语言处理任务，包括但不限于简单问答、基础文本生成、以及初步的情感识别与摘要概括。通过优化算法，该模型在有限的参数下实现了对用户指令的有效理解，能够为用户提供快速且直接的交互反馈。,2024-12-30 14:10:00
internlm2_5-20b-chat,上海人工智能实验室,书生浦语,TEXT,文本对话,20B,32768,13,,,N/A,InternLM2.5-Chat-20B是InternLM2.5研发的一款前沿聊天模型，拥有高达200亿参数。该模型在逻辑推理能力方面表现出色，其数学推理性能超越了Llama3和Gemma2-9B等模型。凭借100万长度的上下文窗口，它在处理长上下文任务（如LongBench）方面表现出众，能够近乎完美地在海量信息中精准定位所需内容。此外，InternLM2.5-Chat-20B支持从超过100个网页中收集信息，并在指令遵循、工具选择和反思等方面展现出卓越的工具利用能力。这些特性共同奠定了InternLM2.5-Chat-20B在聊天模型性能方面的新标杆。,2024-12-30 14:08:27
Qwen2.5-3B-Instruct,阿里云,通义千问,TEXT,文本对话,3B,32768,34,,,N/A,Qwen2.5-3B-instruct是阿里云通义千问大模型系列中的高级版本，拥有30亿参数规模，并集成了先进的指令调优技术。该模型在庞大的多样化预训练数据集上进行了深度训练，不仅掌握了广泛的语言知识，还通过指令调优显著提升了对复杂指令的理解和执行能力。Qwen2.5-3B-instruct擅长处理各种语言任务，包括问答、文本生成、逻辑推理、情感分析、摘要提取等，其优化的指令理解能力使得模型能够更准确地捕捉用户意图，提供更加智能、灵活且个性化的交互体验。这一版本适用于更多元化的应用场景，旨在满足用户对高质量语言处理能力的需求。,2024-12-20 18:32:43
Qwen2.5-1.5B-Instruct,阿里云,通义千问,TEXT,文本对话,1.5B,32768,15,,,N/A,Qwen2.5-1.5B-instruct是阿里云通义千问大模型系列中的一个特定版本，它在原有的Qwen2.5-1.5B（15亿参数规模的大语言模型）基础上，进一步融入了指令调优技术。这一版本通过精心设计的指令数据集进行训练，使得模型能够更好地理解和执行各种复杂的语言指令，包括但不限于问答、文本生成、逻辑推理、摘要提取等任务。Qwen2.5-1.5B-instruct旨在提供更加人性化、灵活且准确的交互体验，满足更广泛的应用场景需求。,2024-12-20 18:32:06
Qwen2.5-14B,阿里云,通义千问,TEXT,文本对话,14B,32768,35,,,N/A,Qwen2.5-14B是阿里云通义千问大模型系列中的产品，拥有惊人的140亿参数规模，代表了自然语言处理领域的最前沿技术。该模型基于Transformer架构的深化设计，经过海量且高度多样化的预训练数据集进行深度训练，这些数据集广泛涵盖了网络文本、专业书籍、学术论文、程序代码、新闻报道、社交媒体内容等多个领域。Qwen2.5-14B凭借其卓越的语言理解和生成能力，能够出色地完成问答、文本创作、逻辑推理、情感分析、摘要生成、对话系统构建、代码理解与生成等一系列复杂任务。其无与伦比的性能和广泛的应用潜力，使得Qwen2.5-14B成为推动人工智能和语言智能领域发展的核心动力，为企业和个人用户提供了前所未有的智能体验和服务。,2024-12-20 18:31:27
Qwen2.5-7B,阿里云,通义千问,TEXT,文本对话,7B,32768,14,,,N/A,Qwen2.5-7B是阿里云通义千问大模型系列中的旗舰级产品，拥有高达70亿参数的庞大模型规模。这款模型基于Transformer架构，并在超大规模的多样化预训练数据集上进行了深度训练，这些数据集覆盖了广泛的网络文本、专业书籍、学术论文、程序代码以及社交媒体内容等。Qwen2.5-7B凭借其强大的语言理解和生成能力，能够轻松应对问答、文本创作、逻辑推理、情感分析、摘要生成、代码理解等多种复杂任务。其卓越的性能和广泛的应用潜力，使得Qwen2.5-7B成为推动自然语言处理领域发展的强大引擎，为企业和个人用户提供了前所未有的语言智能支持。,2024-12-20 18:30:52
Qwen2.5-3B,阿里云,通义千问,TEXT,文本对话,3B,32768,14,,,N/A,Qwen2.5-3B是阿里云通义千问大模型系列中的一款强大语言模型，具备30亿参数的庞大规模。该模型基于先进的Transformer架构，经过海量且多样化的预训练数据集深度训练，这些数据涵盖了广泛的网络文本、专业文献、学术论文、程序代码等多种类型。Qwen2.5-3B不仅能够准确理解自然语言，还能进行流畅的文本生成、逻辑推理、情感分析、摘要提取等多种任务。其卓越的语言处理能力和广泛的适用性，使得Qwen2.5-3B成为众多自然语言处理任务中的理想选择，为企业和个人用户提供了高效、智能的语言解决方案。,2024-12-20 18:30:10
Qwen2.5-1.5B,阿里云,通义千问,TEXT,文本对话,1.5B,32768,14,,,N/A,通义千问2.5-1.5B（Qwen-1.5B）是阿里云推出的通义千问大模型系列中的又一力作，拥有15亿参数规模，同样基于先进的Transformer架构构建而成的大语言模型。该模型在海量且多元化的预训练数据集上进行了深度训练，这些数据涵盖了广泛的网络文本、专业文献、程序代码等多种类型，旨在提供更为精准和全面的语言理解与生成能力。,2024-12-20 18:26:19
Yi-6B-Chat,零一万物,零一万物,TEXT,文本对话,6B,4096,26,,,N/A,Yi-6B-Chat是由01.AI开发的开源双语大语言模型，专注于提供强大的自然语言处理能力。它支持中英双语，并在语言理解、常识推理和阅读理解等多个领域表现出色。模型完全开源，适用于多语言交流和处理，支持微调和量化，以适应各种硬件环境和用途。,2024-12-19 17:52:06
deepseek-llm-7b-chat,杭州深度求索人工智能基础技术研究有限公司,DeepSeek,TEXT,文本对话,7B,4096,53,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1319627861936246784/v1/chat/completions,DeepSeek-LLM-7B-Chat 是一个基于大规模语言模型（LLM）的对话模型，拥有70亿参数。它经过大量数据训练，能够理解和生成自然语言，适用于多种对话场景。该模型具备较强的上下文理解能力，能够进行流畅、连贯的对话，支持多轮交互。它在问答、聊天、信息检索等任务中表现出色，适用于智能客服、虚拟助手等应用。,2024-12-19 17:50:48
Glm-4-9B-Chat,智谱AI,智谱清言,TEXT,文本对话,9B,32768,48,,,,GLM-4-9B-Chat是由智谱AI和清华大学KEG实验室联合研发的新一代开源双语对话预训练模型，具备90亿参数一个强大的预训练语言模型，支持多轮对话、网页浏览、代码执行、自定义工具调用和长文本推理等高级功能。它支持26种语言，包括中文、英文、日语、韩语和德语等，具备长文本处理能力，支持最大128K的上下文长度，约等于25万个中文字符。,2024-12-19 17:17:23
Qwen2-7B-Instruct,阿里,通义千问,TEXT,文本对话,7B,32768,27,,,N/A,"Qwen2-7B-Instruct是Qwen2系列中的一款70亿参数的大型语言模型，它经过指令微调，擅长理解和生成指令性文本。该模型支持长达131,072个令牌的上下文长度，能够处理大量输入。在多个基准测试中，Qwen2-7B-Instruct展现了出色的性能，特别是在编码、数学和推理等领域。它在Humaneval数据集上的编程任务中达到了79.9%的准确率，显示了其在编程领域的强大能力。此外，Qwen2-7B-Instruct在长文本处理方面也有显著优势，能够处理高达128Ktoken的上下文长度。",2024-12-19 17:15:11
Qwen2.5-14B-Instruct,阿里,通义千问,TEXT,文本对话,14B,32768,45,,,,Qwen2.5-14B-Instruct是由阿里云推出的大型语言模型，具备140亿参数，是Qwen系列中性能更为强大的版本之一。该模型经过广泛的数据训练，擅长处理复杂的自然语言处理任务，如文本生成、语义理解与对话交互。它特别优化了对指令的解析和执行能力，能够准确地根据用户指示完成多样化任务，适用于构建智能客服、内容创作助手等多种应用场景，提供高效、精准的服务。,2024-12-19 17:13:33
Qwen2.5-7B-Instruct,阿里,通义千问,TEXT,文本对话,7B,32768,34,,,,Qwen2.5-7B-Instruct是阿里云开发的先进多模态预训练模型，拥有70亿参数。它基于大规模语料库进行训练，能深入理解自然语言指令，广泛适用于文本生成、问答系统、对话代理等场景。此版本特别强化了遵循指令的能力，能够根据用户提供的指导或规则完成特定任务，提供更精准、个性化的服务体验。,2024-12-19 17:12:01
Qwen2.5-72B-Instruct,阿里,通义千问,TEXT,文本对话,72B,32768,113,,,,Qwen2.5-72B-Instruct是阿里云推出的超大规模语言模型，拥有720亿参数，代表了Qwen系列中的顶尖性能。此模型基于海量多源语料训练而成，具备卓越的自然语言理解与生成能力。它在指令跟随性方面进行了深度优化，可以精准解析并执行复杂任务，适用于智能客服、内容创作、自动写作等高级应用领域。凭借其强大的计算能力和精细调校，Qwen2.5-72B-Instruct为用户提供高度定制化和高效的解决方案。,2024-12-19 16:59:56
Qwen2.5-32B-Instruct,阿里,通义千问,TEXT,文本对话,32B,32768,56,,,,Qwen2.5-32B-Instruct是阿里云推出的超大规模语言模型，拥有720亿参数，代表了Qwen系列中的顶尖性能。此模型基于海量多源语料训练而成，具备卓越的自然语言理解与生成能力。它在指令跟随性方面进行了深度优化，可以精准解析并执行复杂任务，适用于智能客服、内容创作、自动写作等高级应用领域。凭借其强大的计算能力和精细调校，Qwen2.5-32B-Instruct为用户提供高度定制化和高效的解决方案。,2024-12-19 16:49:34
internlm2.5-20b-chat,上海人工智能实验室,书生浦语,TEXT,文本对话,20B,32768,35,,,,InternLM2.5-20B-Chat 是书生·浦语大模型的第 2.5 代版本，具备 200 亿参数，专为对话和实用场景优化。其核心特点包括：支持百万长度的上下文窗口，显著增强的推理能力和复杂任务处理能力（如数学推理和代码生成），且开源支持便捷部署，兼容多种推理框架如 Transformers 和 LMDeploy，为开发者提供高效灵活的应用选择。,2024-12-19 09:57:41
internlm2.5-7b-chat,上海人工智能实验室,书生浦语,TEXT,文本对话,7B,32768,14,,,,InternLM2.5-7B-Chat 是书生·浦语大模型的第 2.5 代版本，具备 70 亿参数，专为对话和实用场景优化。其核心特点包括：支持百万长度的上下文窗口，显著增强的推理能力和复杂任务处理能力（如数学推理和代码生成），且开源支持便捷部署，兼容多种推理框架如 Transformers 和 LMDeploy，为开发者提供高效灵活的应用选择。,2024-12-19 09:55:07
Qwen2-72B,阿里云,通义千问,TEXT,文本对话,72B,32768,29,,,N/A,Qwen2是Qwen大语言模型的720亿参数的新系列。与最先进的开源语言模型（包括之前发布的 Qwen1.5）相比，Qwen2 总体上超越了大多数开源模型，并在针对语言理解、语言生成、多语言能力的一系列基准测试中展现了与专有模型的竞争力。,2024-12-18 16:09:07
Qwen2-7B,阿里云,通义千问,TEXT,文本对话,7B,32768,5,,,N/A,Qwen2-7B是由阿里云开发的大型语言模型系列中的一个版本，具有大约70亿个参数。该模型在一系列针对语言理解，语言生成，多语言能力，编码，数学，推理等的基准测试中表现出对专有模型的竞争力。,2024-12-18 16:08:25
Qwen2-1.5B,阿里云,通义千问,TEXT,文本对话,1.5B,32768,24,,,N/A,Qwen2 是 Qwen 大型语言模型的新系列。该仓库包含了 Qwen2 的15亿参数基础语言模型。与最新的开源语言模型（包括之前发布的 Qwen1.5）相比，Qwen2 在语言理解、语言生成、多语言能力、编程、数学、推理等一系列基准测试中，普遍超越了大多数开源模型，并在许多方面展现出对专有模型的竞争力。,2024-12-18 16:04:16
Qwen2-0.5B,阿里云,通义千问,TEXT,文本对话,0.5B,32768,9,,,N/A,Qwen2 是 Qwen 大型语言模型的新系列。该仓库包含了 Qwen2 的5亿参数基础语言模型。与最新的开源语言模型（包括之前发布的 Qwen1.5）相比，Qwen2 在语言理解、语言生成、多语言能力、编程、数学、推理等一系列基准测试中，普遍超越了大多数开源模型，并在许多方面展现出对专有模型的竞争力。,2024-12-18 16:02:57
Qwen-72B,阿里云,通义千问,TEXT,文本对话,72B,32768,23,,,N/A,"通义千问是阿里云研发的通义千问大模型系列。基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-12-18 16:01:45
Qwen-14B,阿里云,通义千问,TEXT,文本对话,14B,32768,17,,,N/A,"通义千问是阿里云研发的通义千问大模型系列。基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-12-18 16:00:20
Mixtral-8x7B-v0.1,Mistral AI,Mistral,TEXT,文本对话,56B,32768,19,,,N/A,Mixtral-8x7B 大型语言模型 ( LLM ) 是一种预训练的生成式稀疏专家混合模型。,2024-12-18 15:58:50
Mistral-7B-v0.1,Mistral AI,Mistral,TEXT,文本对话,,32768,7,,,N/A,Mistral-7B-v0.1 大型语言模型 ( LLM ) 是一个预训练的生成文本模型，具有 70 亿个参数。,2024-12-18 15:56:36
Qwen-7B,阿里云,通义千问,TEXT,文本对话,7B,32768,9,,,N/A,"通义千问是阿里云研发的通义千问大模型系列。基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-12-18 15:55:08
Qwen1.5-14B,阿里云,通义千问,TEXT,文本对话,14B,32768,8,,,N/A,通义千问1.5-14B（Qwen-14B）是阿里云倾力打造的通义千问大模型系列中的140亿参数规模版本，它基于先进的Transformer架构构建而成，并在海量且多元化的预训练数据上进行了深度训练。这些数据涵盖了广泛的网络文本资源、权威的专业书籍以及丰富的代码样本，确保了模型在理解、生成及推理能力上的卓越表现。,2024-12-13 18:48:55
QwQ-32B,阿里云,通义千问,TEXT,文本对话,32B,32768,216,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1347665821397590016/v1/chat/completions,QwQ 是通义千问（Qwen）系列的推理模型。与传统的指令微调模型相比，具备思考和推理能力的 QwQ 在下游任务中能够实现显著提升的性能表现，尤其是在处理难题方面。QwQ-32B 是一款中型推理模型，它能够与当前最先进的推理模型（如 DeepSeek-R1、o1-mini 等）竞争并取得相当出色的性能表现。,2024-12-02 00:00:00
Qwen1.5-14B-Chat,通义千问,通义千问,TEXT,文本对话,14B,32768,19,,,,"通义千问-14B（Qwen-14B）是阿里云研发的通义千问大模型系列的140亿参数规模的模型，是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-09-03 18:43:06
ChatGLM3-6B,智谱.AI,智谱清言,TEXT,文本对话,6B,8192,46,,,,智谱AI与清华KEG实验室发布的中英双语对话模型，相比前两代，具备更强大的基础模型，同时原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。,2024-05-20 15:18:22
Qwen1.5-7B,阿里云,通义千问,TEXT,文本对话,7B,32768,20,,,N/A,"通义千问1.5-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型，是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-05-20 15:16:07
Qwen1.5-7B-Chat,通义千问,通义千问,TEXT,文本对话,7B,32768,14,,,N/A,"通义千问-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型，是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-05-20 15:16:06
Qwen-7B-Chat,通义千问,通义千问,TEXT,文本对话,7B,4096,18,,,,"通义千问-7B（Qwen-7B）是阿里云研发的通义千问大模型系列的70亿参数规模的模型，是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-05-20 15:16:06
Qwen-14B-Chat,通义千问,通义千问,TEXT,文本对话,14B,4096,39,,,N/A,"通义千问-14B（Qwen-14B）是阿里云研发的通义千问大模型系列的140亿参数规模的模型，是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。",2024-05-20 15:12:44
bge-m3,BAAI,bge,VECTOR,文本对话,568M,8192,126,,,https://zhenze-huhehaote.cmecloud.cn/inference-api/exp-api/inf-1377771300653678592/v1/embeddings,BGE-M3是智源推出的新一代通用语义向量模型，支持100多种语言，具备高效的多语言检索能力。它能处理不同粒度的文本，最大输入长度为8192，集成了多种检索功能，性能优异。,2024-05-08 00:00:00
